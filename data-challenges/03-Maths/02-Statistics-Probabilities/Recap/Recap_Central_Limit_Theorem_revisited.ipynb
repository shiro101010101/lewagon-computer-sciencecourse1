{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem (CLT) - Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Introduction to the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è You can skip this section of the `Recap - Central Limit Theorem - Revisited` if you had time to read it during the `Challenge - The Central Limit Theorem - A first approach`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two convergence theorems revolutionized the disciplines of probability and statistics:**\n",
    "- **`LLN`: the Law of Large Numbers**\n",
    "- **`CLT`: the Central Limit Theorem**\n",
    "\n",
    "üßëüèª‚Äçüè´ What is the CLT ? According to [Wikipedia](https://en.wikipedia.org/wiki/Central_limit_theorem)\n",
    "\n",
    "> In probability theory, the central limit theorem (CLT) establishes that, in many situations, when independent random variables are summed up, their properly normalized sum tends towards a `Gaussian/normal distribution` (informally a `bell curve`) even if the original variables themselves are not normally distributed. The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ  Interpreting and experimenting the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ  Let's illustrate how to use the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) in a dataset:\n",
    "\n",
    "* Given a population, let's consider a feature (example: size, weight, salary, etc...) for each individual.\n",
    "\n",
    "\n",
    "üöÄ  The important takeaway of these two theorems is that **whatever the shape of the distribution** of a given feature over the population **is**, **the distribution of the (sampled) mean<u>S</u> tends to be Gaussian**:\n",
    "* `the mean of the means` = $ \\mu$ (Law of Large Numbers)\n",
    "* `the standard deviation of the means` = $ \\frac{\\sigma}{\\sqrt{n}} $  (Central Limit Theorem)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/IllustrationCentralTheorem.png/400px-IllustrationCentralTheorem.png)\n",
    "\n",
    "üí°  We can wrap it up the following way:\n",
    "\n",
    "$$ \\large \\bar{X} \\approx_{n \\rightarrow \\infty} \\mathcal{N}(\\mu,\\frac{\\sigma}{\\sqrt{n}}) $$\n",
    "\n",
    "üë©üèª‚Äçüî¨  Let's verify this experimentally!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  üöÄ Let's get started !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ In this challenge, we will use the `tips` dataset from the `seaborn` library to illustrate the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Scientific libraries\n",
    "import scipy.stats as stats\n",
    "# Data Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Load the `\"total_bill\"` dataset from `seaborn` into a `df` variable and display the first rows ‚ùì\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    You can use <a href=\"https://seaborn.pydata.org/generated/seaborn.load_dataset.html\"><code>seaborn.load_dataset</code></a>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßê Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many rows are available in the dataset ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä Plot the distribution of the `total_bill` column in the restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x = \"total_bill\", data = df, kde = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the [**skewness**](https://whatis.techtarget.com/definition/skewness) value of this distribution ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create two variables `mu` and `sigma` to store the mean and standard deviation of tips ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≤ Sampling the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Pick randomly - and with replacement - 10 rows of the dataset, and compute the mean $ \\bar{X} $ of this sample.\n",
    "\n",
    "Run this cell a few times.\n",
    "* Do you get the same result each time?\n",
    "* Did you expect it ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"total_bill\"].sample(1000, replace=True).mean()\n",
    "df[\"total_bill\"].sample(5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Create a `means` list storing a list of means of $N$ samples (each of them with size $n$).\n",
    "\n",
    "Start with $n = 5$ and $N = 10$\n",
    "\n",
    "üìä In the same cell, **plot** the distribution of `means`. \n",
    "\n",
    "üïµÔ∏è‚Äç‚ôÄÔ∏è Let's play with the *sample size n* and the *number of samples N*:\n",
    "- Keep *n* constant, increase N. What do you observe ?\n",
    "    - Plot a grid of 6 distributions playing with  $ n \\in \\{ 1, 5, 50, 100, 500, 1000 \\}$\n",
    "- Then, increase *n* and test another range for *N*. What do you observe ?\n",
    "    - Plot a grid of 6 distributions playing with  $ N \\in \\{ 10, 20, 30, 50, 100, 500 \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Playing with the `sample size`</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As *n* increases:\n",
    "* the distribution of the means converges towards the theoretical mean $ \\mu $ (LGN)\n",
    "* the variance around $ \\mu $ tends towards 0 (indeed: $ \\large \\frac{\\sigma}{\\sqrt{n}} \\rightarrow_{n \\rightarrow \\infty} 0 $)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Playing with the `number_of_samples`</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customers in one sample\n",
    "n = 200\n",
    "\n",
    "# Number of samples\n",
    "list_of_N = [10,20,30,50, 100, 500]\n",
    " \n",
    "# Plot 6 graphs : 2 rows by 3 columns for the 6 values of N\n",
    "fix,axes = plt.subplots(nrows=2,ncols=3,figsize=(15,10))\n",
    "for N, ax in zip(list_of_N,axes.flat):\n",
    "    means = [df[\"total_bill\"].sample(n, replace=True).mean() for i in range(N)]\n",
    "    ax.set_title(f\"N={N}\")\n",
    "    ax.set_xlim(0, 40)\n",
    "    sns.histplot(means,bins=10,ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As *N* increases:\n",
    "* the distribution of the means is less noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë©üèª‚Äçüíª Verifying the CLT with simulations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/IllustrationCentralTheorem.png/400px-IllustrationCentralTheorem.png)\n",
    "\n",
    "$$ \\large \\bar{X} \\approx_{n \\rightarrow \\infty} \\mathcal{N}(\\mu,\\frac{\\sigma}{\\sqrt{n}}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• Let's verify the Central Limit Theorem computationally \n",
    "\n",
    "For each value of `n`:\n",
    "- Compare `mu` with the mean of means\n",
    "- Compare `sigma` with the standard deviation of the means, (don't forget the $\\sqrt n$ adjustment)\n",
    "- Compute the `skewness` of the sampling distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = df[\"total_bill\"].mean()\n",
    "sigma = df[\"total_bill\"].std()\n",
    "skew = df[\"total_bill\"].skew()\n",
    "kurtosis = df[\"total_bill\"].kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mu: {round(mu,2)}\")\n",
    "print(f\"sigma: {round(sigma,2)}\")\n",
    "print(f\"skew: {round(skew,2)}\")\n",
    "print(f\"kurtosis: {round(kurtosis,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚≠êÔ∏è Real-life application of the CLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's consider `n` =  100 rows **sampled from the dataset**. What is the probability that the cumulated total bill is **lower than 1800‚Ç¨**? \n",
    "\n",
    "üöÄ `n > 30` is enough to apply the Central Limit Theorem. The distribution of the sampled means follows a **`Gaussian Distribution`** (already referred as a **`Normal Distribution`**)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the  **`pdf`** (a.k.a. `probability density function`) of the sampled means of the total bills. You can use ***[`scipy.stats.norm`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html)***\n",
    "\n",
    "$$ \\large \\bar{X} \\approx_{n \\rightarrow \\infty} \\mathcal{N}(\\mu,\\frac{\\sigma}{\\sqrt{n}}) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ We'll revisit the concept of Gaussian Variable during the lecture `Statistical Inference`. For this kind of random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the probability we are looking for? Use the `cdf` method to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bar.cdf(target_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compute the z-score for the value `18‚Ç¨`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (target_mean - mu) / (sigma / np.sqrt(n))\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the normal distribution (0, 1) and a red dot for the target (use the `pdf`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_norm = stats.norm(0, 1)\n",
    "x = np.linspace(-4, 4, 100)\n",
    "y = true_norm.pdf(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.scatter(z, true_norm.pdf(z), c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ And... that's the end of this module for today !\n",
    "\n",
    "üíæ Again, you know the routine: `git add/commit/push` !\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üéâ Massive congratulations for making it to the end of the two Mathematics modules! \n",
    "\n",
    "\n",
    "ü§© If you fell in love with math, look at the following video: [**`The Map of Mathematics`**](https://www.youtube.com/watch?v=OmJ-4B-mS-Y) (11 min - 9M views on Youtube)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://live.staticflickr.com/272/32264483720_c51bdde679_n.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üìÜ So, now **how do you prepare yourself to enter the world of `Decision Science`** ? \n",
    "\n",
    "- üêç **`Python For Data Science`** :\n",
    "    - the more we progress in the bootcamp, the more important you will have to be proficient in Python so that you can focus on the new Data Science concepts and not the programming questions !\n",
    "    - _Example_: think about a professionnal tennis player: before a game,  he/she elaborates a strategy with the coach to beat the opponent, not how to make a good serve or how to do a top spin !\n",
    "    \n",
    "- üî¢ **`SQL`**:\n",
    "    - Mastering databases'queries is at the heart of any _Data Science and Analytics job_, even before Python for Data Analysts\n",
    "    - It is fundamental that you master how to _join tables_ with SQL, we will re-use the concepts of _merging tables_ extensively with _Pandas_ and you will have to do it not only during your projects but also afterwards in your next job\n",
    "    \n",
    "- üêº **`Pandas/Numpy`**\n",
    "    - The more expert you are at manipulating data with these two libraries, the more you can focus on adding value to your analysis \n",
    "    - The same way Excel masters will outshine their colleagues in Finance, Pandas/Numpy wizards will be much faster on focusing on handling new data.\n",
    "    \n",
    "- üßÆ **`Maths`**:\n",
    "    - `Algebra`: You must be comfortable dealing with Matrixes, DataFrames, Numpy Arrays! We will use them everywhere, even for Computer Vision and Image Preprocessing. We do not ask you to be an expert taking a full Linear Algebra course at the university like [MIT - Gilbert Strang - Linear Algebra](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/) (Open Source course on MIT OpenCourseWare) but at least, be proficient with Matrix Shapes, Transpose, Inverse, Matrix Multiplications\n",
    "    - `Probability and Statistics`: We will re-use the Gaussian Distributions and the Central Limit Theorems during the next module, so make sure you understood these concepts and list all the remaining questions you would like to ask to your teachers and TA !\n",
    "\n",
    "üëâ These topics should be your priorities! You can review a bit later challenges related to Data Visualisation and Data Sourcing: for example if you still have time after reviewing the priorities or before starting your Data Science Projects.\n",
    "\n",
    "\n",
    "üëã See you soon ! üëã\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
