{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrocardiograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Import the [`electrocardiograms.csv`](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_dataset.csv) dataset and display its first 5 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.816425</td>\n",
       "      <td>0.558776</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>0.236715</td>\n",
       "      <td>0.236715</td>\n",
       "      <td>0.210950</td>\n",
       "      <td>0.177134</td>\n",
       "      <td>0.161031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.084894</td>\n",
       "      <td>0.167291</td>\n",
       "      <td>0.215980</td>\n",
       "      <td>0.282147</td>\n",
       "      <td>0.343321</td>\n",
       "      <td>0.390762</td>\n",
       "      <td>0.479401</td>\n",
       "      <td>0.590512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041758</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.252747</td>\n",
       "      <td>0.389011</td>\n",
       "      <td>0.375824</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.380220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901993</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.508306</td>\n",
       "      <td>0.327243</td>\n",
       "      <td>0.192691</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.064784</td>\n",
       "      <td>0.049834</td>\n",
       "      <td>0.038206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.066910</td>\n",
       "      <td>0.164234</td>\n",
       "      <td>0.237226</td>\n",
       "      <td>0.310219</td>\n",
       "      <td>0.360097</td>\n",
       "      <td>0.383212</td>\n",
       "      <td>0.446472</td>\n",
       "      <td>0.529197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956916</td>\n",
       "      <td>0.902494</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.774554</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.917411</td>\n",
       "      <td>0.834821</td>\n",
       "      <td>0.790179</td>\n",
       "      <td>0.774554</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.345982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915361</td>\n",
       "      <td>0.884013</td>\n",
       "      <td>0.771160</td>\n",
       "      <td>0.592476</td>\n",
       "      <td>0.510972</td>\n",
       "      <td>0.463950</td>\n",
       "      <td>0.410658</td>\n",
       "      <td>0.426332</td>\n",
       "      <td>0.420063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954424</td>\n",
       "      <td>0.713137</td>\n",
       "      <td>0.430295</td>\n",
       "      <td>0.367292</td>\n",
       "      <td>0.313673</td>\n",
       "      <td>0.282842</td>\n",
       "      <td>0.264075</td>\n",
       "      <td>0.261394</td>\n",
       "      <td>0.252011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.980354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766208</td>\n",
       "      <td>0.176817</td>\n",
       "      <td>0.172888</td>\n",
       "      <td>0.119843</td>\n",
       "      <td>0.104126</td>\n",
       "      <td>0.070727</td>\n",
       "      <td>0.080550</td>\n",
       "      <td>0.055010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.397906</td>\n",
       "      <td>0.565445</td>\n",
       "      <td>0.692845</td>\n",
       "      <td>0.699825</td>\n",
       "      <td>0.652705</td>\n",
       "      <td>0.661431</td>\n",
       "      <td>0.692845</td>\n",
       "      <td>0.678883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968273</td>\n",
       "      <td>0.930670</td>\n",
       "      <td>0.927145</td>\n",
       "      <td>0.901293</td>\n",
       "      <td>0.806110</td>\n",
       "      <td>0.643948</td>\n",
       "      <td>0.361927</td>\n",
       "      <td>0.251469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932070</td>\n",
       "      <td>0.684044</td>\n",
       "      <td>0.363349</td>\n",
       "      <td>0.210111</td>\n",
       "      <td>0.109005</td>\n",
       "      <td>0.096367</td>\n",
       "      <td>0.074250</td>\n",
       "      <td>0.091627</td>\n",
       "      <td>0.090047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990164</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.276503</td>\n",
       "      <td>0.167213</td>\n",
       "      <td>0.165027</td>\n",
       "      <td>0.121311</td>\n",
       "      <td>0.102732</td>\n",
       "      <td>0.112568</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.722642</td>\n",
       "      <td>0.813208</td>\n",
       "      <td>0.737736</td>\n",
       "      <td>0.692453</td>\n",
       "      <td>0.666038</td>\n",
       "      <td>0.696226</td>\n",
       "      <td>0.722642</td>\n",
       "      <td>0.626415</td>\n",
       "      <td>0.345283</td>\n",
       "      <td>0.196226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0   0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1   1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2   0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3   0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4   0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "5   1.000000  0.940419  0.816425  0.558776  0.314010  0.236715  0.236715   \n",
       "6   0.000000  0.022472  0.084894  0.167291  0.215980  0.282147  0.343321   \n",
       "7   0.000000  0.041758  0.114286  0.252747  0.389011  0.375824  0.342857   \n",
       "8   1.000000  0.901993  0.744186  0.508306  0.327243  0.192691  0.093023   \n",
       "9   0.000000  0.007299  0.066910  0.164234  0.237226  0.310219  0.360097   \n",
       "10  0.904762  0.993197  1.000000  0.956916  0.902494  0.857143  0.802721   \n",
       "11  0.774554  0.861607  0.917411  0.834821  0.790179  0.774554  0.803571   \n",
       "12  1.000000  0.915361  0.884013  0.771160  0.592476  0.510972  0.463950   \n",
       "13  1.000000  0.954424  0.713137  0.430295  0.367292  0.313673  0.282842   \n",
       "14  0.980354  1.000000  0.766208  0.176817  0.172888  0.119843  0.104126   \n",
       "15  0.000000  0.165794  0.397906  0.565445  0.692845  0.699825  0.652705   \n",
       "16  1.000000  1.000000  0.968273  0.930670  0.927145  0.901293  0.806110   \n",
       "17  1.000000  0.932070  0.684044  0.363349  0.210111  0.109005  0.096367   \n",
       "18  1.000000  0.990164  0.696175  0.276503  0.167213  0.165027  0.121311   \n",
       "19  0.722642  0.813208  0.737736  0.692453  0.666038  0.696226  0.722642   \n",
       "\n",
       "         x_8       x_9      x_10  ...     x_179     x_180     x_181  x_182  \\\n",
       "0   0.413858  0.426966  0.485019  ...  0.000000  0.000000  0.000000    0.0   \n",
       "1   0.346429  0.314286  0.305357  ...  0.000000  0.000000  0.000000    0.0   \n",
       "2   0.656613  0.421114  0.288863  ...  0.294664  0.295824  0.301624    0.0   \n",
       "3   0.177019  0.270186  0.313665  ...  0.000000  0.000000  0.000000    0.0   \n",
       "4   0.108541  0.145907  0.192171  ...  0.000000  0.000000  0.000000    0.0   \n",
       "5   0.210950  0.177134  0.161031  ...  0.000000  0.000000  0.000000    0.0   \n",
       "6   0.390762  0.479401  0.590512  ...  0.000000  0.000000  0.000000    0.0   \n",
       "7   0.353846  0.338462  0.380220  ...  0.000000  0.000000  0.000000    0.0   \n",
       "8   0.064784  0.049834  0.038206  ...  0.000000  0.000000  0.000000    0.0   \n",
       "9   0.383212  0.446472  0.529197  ...  0.000000  0.000000  0.000000    0.0   \n",
       "10  0.777778  0.709751  0.557823  ...  0.000000  0.000000  0.000000    0.0   \n",
       "11  0.808036  0.651786  0.345982  ...  0.000000  0.000000  0.000000    0.0   \n",
       "12  0.410658  0.426332  0.420063  ...  0.000000  0.000000  0.000000    0.0   \n",
       "13  0.264075  0.261394  0.252011  ...  0.000000  0.000000  0.000000    0.0   \n",
       "14  0.070727  0.080550  0.055010  ...  0.000000  0.000000  0.000000    0.0   \n",
       "15  0.661431  0.692845  0.678883  ...  0.000000  0.000000  0.000000    0.0   \n",
       "16  0.643948  0.361927  0.251469  ...  0.000000  0.000000  0.000000    0.0   \n",
       "17  0.074250  0.091627  0.090047  ...  0.000000  0.000000  0.000000    0.0   \n",
       "18  0.102732  0.112568  0.120219  ...  0.000000  0.000000  0.000000    0.0   \n",
       "19  0.626415  0.345283  0.196226  ...  0.000000  0.000000  0.000000    0.0   \n",
       "\n",
       "    x_183  x_184  x_185  x_186  x_187  target  \n",
       "0     0.0    0.0    0.0    0.0    0.0       1  \n",
       "1     0.0    0.0    0.0    0.0    0.0       1  \n",
       "2     0.0    0.0    0.0    0.0    0.0       1  \n",
       "3     0.0    0.0    0.0    0.0    0.0       1  \n",
       "4     0.0    0.0    0.0    0.0    0.0       1  \n",
       "5     0.0    0.0    0.0    0.0    0.0       1  \n",
       "6     0.0    0.0    0.0    0.0    0.0       1  \n",
       "7     0.0    0.0    0.0    0.0    0.0       1  \n",
       "8     0.0    0.0    0.0    0.0    0.0       1  \n",
       "9     0.0    0.0    0.0    0.0    0.0       1  \n",
       "10    0.0    0.0    0.0    0.0    0.0       1  \n",
       "11    0.0    0.0    0.0    0.0    0.0       1  \n",
       "12    0.0    0.0    0.0    0.0    0.0       1  \n",
       "13    0.0    0.0    0.0    0.0    0.0       1  \n",
       "14    0.0    0.0    0.0    0.0    0.0       1  \n",
       "15    0.0    0.0    0.0    0.0    0.0       1  \n",
       "16    0.0    0.0    0.0    0.0    0.0       1  \n",
       "17    0.0    0.0    0.0    0.0    0.0       1  \n",
       "18    0.0    0.0    0.0    0.0    0.0       1  \n",
       "19    0.0    0.0    0.0    0.0    0.0       1  \n",
       "\n",
       "[20 rows x 188 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"./data/ML_Electrocardiograms_dataset.csv\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19565, 188)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ℹ️ Each obervation of the dataset is a numerically represented heartbeat, taken from a patient's electrocardiogram (ECG). The target is binary and defines whether the heartbeat is at risk of cardiovascular disease [1] or not [0]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Plot an observation of each target class to get a visual idea of what the numbers represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.0290e+03, 1.1300e+02, 9.3000e+01, ..., 4.1200e+02, 1.3590e+03,\n",
       "         1.5913e+04],\n",
       "        [6.5200e+02, 3.9900e+02, 1.5100e+02, ..., 3.3620e+03, 5.5770e+03,\n",
       "         5.8950e+03],\n",
       "        [1.9630e+03, 2.0210e+03, 2.3710e+03, ..., 1.4580e+03, 4.8000e+02,\n",
       "         3.3300e+02],\n",
       "        ...,\n",
       "        [1.9441e+04, 7.0000e+00, 5.0000e+01, ..., 1.0000e+00, 1.0000e+00,\n",
       "         4.0000e+00],\n",
       "        [1.9444e+04, 5.0000e+00, 4.7000e+01, ..., 2.0000e+00, 1.0000e+00,\n",
       "         4.0000e+00],\n",
       "        [1.8117e+04, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "         1.4480e+03]]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 188 BarContainer objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 How many observations of at-risk heartbeats are there? Save your answer as `at_risk_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "data[\"target\"].value_counts()\n",
    "at_risk_count=1448"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 How many observations of healthy heartbeats are there? Save your answer as `healthy_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "healthy_count=18117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ℹ️ In certain cases, the class balance is representative of the true class distribution. This is the case here: the vast majority of people actually have healthy hearts. In such case, we preserve the class distribution inform the model on the reality, and adapt our modelling approach accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /Users/shu/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shu/Desktop/Lewagon/code/shiro101010101/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: dash-2.0.0, anyio-3.3.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "tests/test_class_balance.py::TestClass_balance::test_at_risk_count \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_class_balance.py::TestClass_balance::test_healthy_count \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/class_balance.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed class_balance step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('class_balance',\n",
    "                         healthy = healthy_count,\n",
    "                         at_risk = at_risk_count\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎯 Your task is to flag heartbeats that are at risk of cardiovascular diseases.\n",
    "\n",
    "👇 Let's start by investigating the performance of a `LogisticRegression` on that task. Use cross validation to evaluate the model on the following metrics:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[[\"target\"]]\n",
    "X=data.drop(columns=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0  0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1  1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2  0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3  0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4  0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "\n",
       "        x_8       x_9      x_10  ...     x_178     x_179     x_180     x_181  \\\n",
       "0  0.413858  0.426966  0.485019  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.346429  0.314286  0.305357  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.656613  0.421114  0.288863  ...  0.300464  0.294664  0.295824  0.301624   \n",
       "3  0.177019  0.270186  0.313665  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.108541  0.145907  0.192171  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   x_182  x_183  x_184  x_185  x_186  x_187  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19565, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19565, 187)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19565, 187)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data.loc[:,\"x_1\":\"x_187\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.86313915, 0.86448693, 0.89343095, 0.62062693, 0.77867699]),\n",
       " 'score_time': array([0.00843596, 0.00911307, 0.00628185, 0.00544   , 0.00505114]),\n",
       " 'test_accuracy': array([0.93892154, 0.93892154, 0.93994378, 0.93841043, 0.93968822]),\n",
       " 'test_recall': array([0.29655172, 0.35517241, 0.36206897, 0.32871972, 0.30795848]),\n",
       " 'test_precision': array([0.7107438 , 0.66451613, 0.67741935, 0.66901408, 0.712     ]),\n",
       " 'test_f1': array([0.41849148, 0.46292135, 0.47191011, 0.44083527, 0.42995169])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Los_model=LogisticRegression(max_iter=1000)\n",
    "cv_score=cross_validate(Los_model,X,y,cv=5,\n",
    "                       scoring=[\"accuracy\",\"recall\",\"precision\",\"f1\"])\n",
    "cv_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ What is the model's ratio of correct predictions? Save your answer under variable name `correct_pred_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391771019677997"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "correct_pred_ratio=cv_score[\"test_accuracy\"].mean()\n",
    "correct_pred_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ What percentage of at-risk heartbeats is the model able to flag? Save your answer under variable name `flag_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3300942608280635"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "flag_ratio=cv_score[\"test_recall\"].mean()\n",
    "flag_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ When the model signals an at-risk heartbeat, how often is it correct? Save your answer under variable name `correct_detection_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "correct_detection_ratio=cv_score[\"test_precision\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ What is the model's ability to flag as many at-risk heartbeats as possible while limiting false alarms?  Save your answer under variable name `aggregated_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "aggregated_metric=cv_score[\"test_f1\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ℹ️ By observing the different metrics, you should see that accuracy is deceiving. To understand what is going on, we can observe a breakdown of the model's predictions in a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /Users/shu/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shu/Desktop/Lewagon/code/shiro101010101/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: dash-2.0.0, anyio-3.3.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_accuracy \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_f1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_logistic_regression_evaluation.py::TestLogistic_regression_evaluation::test_recall \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.39s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/logistic_regression_evaluation.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed logistic_regression_evaluation step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('logistic_regression_evaluation',\n",
    "                         accuracy = correct_pred_ratio,\n",
    "                         recall = flag_ratio,\n",
    "                         precision = correct_detection_ratio,\n",
    "                         f1 = aggregated_metric\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Using `plot_confusion_matrix` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html)),  visualize the predictions breakdown of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>💡 Hints</summary>\n",
    "\n",
    "- `plot_confusion_matrix` takes as input a **trained model** and **test data**\n",
    "    \n",
    "- You'll need to go back to the **Holdout method!** You can use Sklearn's `train_test_split()` ([doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n",
    "    \n",
    "- Look into the `normalize` parameter\n",
    "  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "#  heartbeat is at risk of cardiovascular disease [1] or not [0].\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X1,y1=make_classification()\n",
    "X_train,X_test,y_train,y_test=train_test_split(\n",
    "X1,y1,random_state=0)\n",
    "clf=LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "plot_confusion_matrix(clf,X_test,y_test)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ℹ️ The confusion matrix should show that the model is influenced by the class imbalance: it predicts heartbeats to be healthy most of the time. Due to this behaviour, the model is often correct and has a high accuracy. However, it causes it to miss out on many at risk heartbeats: it has a bad recall.\n",
    "\n",
    "👉 This model is therefore poor at the task of **flagging at-risk observations**.\n",
    "\n",
    "⚠️ Don't be fooled by the accuracy and look at the metric that corresponds to your task! ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Would a default KNN classifier perform better at the task of flagging at-risk observations?\n",
    "\n",
    "Save the you answer under `best_model` as \"KNN\" or \"LogisticRegression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577210356759336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_model=KNeighborsClassifier()\n",
    "knn_result=cross_validate(k_model,X,y,scoring=[\"recall\"])\n",
    "knn_result[\"test_recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.330096647178141"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lg_model=LogisticRegression()\n",
    "lg_result=cross_validate(lg_model,X,y,scoring=[\"recall\"])\n",
    "lg_result[\"test_recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.112360</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.322097</td>\n",
       "      <td>0.363296</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.485019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951276</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.803944</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.421114</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300464</td>\n",
       "      <td>0.294664</td>\n",
       "      <td>0.295824</td>\n",
       "      <td>0.301624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.270186</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.327402</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19560</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.049123</td>\n",
       "      <td>0.098246</td>\n",
       "      <td>0.108772</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19561</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564854</td>\n",
       "      <td>0.221757</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>0.087866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.240586</td>\n",
       "      <td>0.290795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>0.991914</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.215633</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.236287</td>\n",
       "      <td>0.198312</td>\n",
       "      <td>0.194093</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>0.093168</td>\n",
       "      <td>0.096273</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19565 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x_1       x_2       x_3       x_4       x_5       x_6       x_7  \\\n",
       "0      0.000000  0.041199  0.112360  0.146067  0.202247  0.322097  0.363296   \n",
       "1      1.000000  0.901786  0.760714  0.610714  0.466071  0.385714  0.364286   \n",
       "2      0.994200  1.000000  0.951276  0.903712  0.917633  0.900232  0.803944   \n",
       "3      0.984472  0.962733  0.663043  0.211180  0.000000  0.032609  0.100932   \n",
       "4      0.619217  0.489324  0.327402  0.110320  0.000000  0.060498  0.108541   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19560  1.000000  0.533333  0.049123  0.098246  0.108772  0.091228  0.101754   \n",
       "19561  1.000000  0.564854  0.221757  0.202929  0.087866  0.000000  0.041841   \n",
       "19562  0.991914  0.735849  0.215633  0.029650  0.061995  0.061995  0.016173   \n",
       "19563  1.000000  0.839662  0.240506  0.215190  0.236287  0.198312  0.194093   \n",
       "19564  0.934783  0.739130  0.335404  0.093168  0.096273  0.071429  0.027950   \n",
       "\n",
       "            x_8       x_9      x_10  ...     x_178     x_179     x_180  \\\n",
       "0      0.413858  0.426966  0.485019  ...  0.000000  0.000000  0.000000   \n",
       "1      0.346429  0.314286  0.305357  ...  0.000000  0.000000  0.000000   \n",
       "2      0.656613  0.421114  0.288863  ...  0.300464  0.294664  0.295824   \n",
       "3      0.177019  0.270186  0.313665  ...  0.000000  0.000000  0.000000   \n",
       "4      0.108541  0.145907  0.192171  ...  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19560  0.084211  0.105263  0.087719  ...  0.000000  0.000000  0.000000   \n",
       "19561  0.150628  0.240586  0.290795  ...  0.000000  0.000000  0.000000   \n",
       "19562  0.010782  0.021563  0.021563  ...  0.000000  0.000000  0.000000   \n",
       "19563  0.143460  0.135021  0.071730  ...  0.000000  0.000000  0.000000   \n",
       "19564  0.015528  0.009317  0.006211  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "          x_181  x_182  x_183  x_184  x_185  x_186  x_187  \n",
       "0      0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1      0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2      0.301624    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3      0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4      0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "...         ...    ...    ...    ...    ...    ...    ...  \n",
       "19560  0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "19561  0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "19562  0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "19563  0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "19564  0.000000    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[19565 rows x 187 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19565, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=\"KNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ℹ️ The KNN classifier should have a much higher recall than the LogisticRegression and therefore is better suited for the task.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /Users/shu/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shu/Desktop/Lewagon/code/shiro101010101/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: dash-2.0.0, anyio-3.3.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_best_model.py::TestBest_model::test_best_model \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/best_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed best_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('best_model',\n",
    "                         model = best_model,\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the KNN model has the best recall, let's check out its performance accross all the other classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇 Print out a `classification_report` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)) of the KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> 💡 Hint  </summary>\n",
    "    \n",
    "You'll need to pass model predictions to `classification_report`. Sklearn's `cross_val_predict` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)) might help 😉\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "from sklearn import datasets,linear_model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred=cross_val_predict(k_model,X,y,cv=3)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.99      1.00      0.99     18117\n",
      "     class 1       0.94      0.84      0.89      1448\n",
      "\n",
      "    accuracy                           0.98     19565\n",
      "   macro avg       0.96      0.92      0.94     19565\n",
      "weighted avg       0.98      0.98      0.98     19565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n",
    "\n",
    "print(classification_report(y,y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Looking at the classification report, what is the model's ratio of correctly predicted at-risk heartbeats? Save your answer as a float under `correct_atrisk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "correct_atrisk_predictions=0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /Users/shu/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shu/Desktop/Lewagon/code/shiro101010101/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: dash-2.0.0, anyio-3.3.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_precision.py::TestPrecision::test_precision \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/precision.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed precision step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('precision',\n",
    "                         precision = correct_atrisk_predictions,\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎯 A patient comes to you for a second opinion on what he was told may be an at risk heartbeat.  Download its data [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Electrocardiograms_new_patient.csv).\n",
    "\n",
    "\n",
    "❓ According to your optimal model, is he at risk or not?  \n",
    "\n",
    "Save the prediction of your model under variable name `prediction` as \"at risk\" or \"healthy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956916</td>\n",
       "      <td>0.902494</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2  x_3       x_4       x_5       x_6       x_7       x_8  \\\n",
       "0  0.904762  0.993197  1.0  0.956916  0.902494  0.857143  0.802721  0.777778   \n",
       "\n",
       "        x_9      x_10  ...  x_178  x_179  x_180  x_181  x_182  x_183  x_184  \\\n",
       "0  0.709751  0.557823  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   x_185  x_186  x_187  \n",
       "0    0.0    0.0    0.0  \n",
       "\n",
       "[1 rows x 187 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "new_data=pd.read_csv(\"./data/ML_Electrocardiograms_new_patient.csv\")\n",
    "new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shu/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model.predict(new_data)\n",
    "prediction=\"at risk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /Users/shu/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shu/Desktop/Lewagon/code/shiro101010101/data-challenges/05-ML/03-Performance-metrics/02-Electrocardiograms\n",
      "plugins: dash-2.0.0, anyio-3.3.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_prediction.py::TestPrediction::test_prediction_at_risk \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('prediction',\n",
    "                         prediction = prediction\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏁"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
