{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ARIMA model for non-seasonal time-serie forecast\n",
    "\n",
    "Our goal in this challenge is to apply the basic concepts of time series analysis on one-dimension data\n",
    "\n",
    "In this challenge, we'll go through the following steps : \n",
    "1. load and visualize the data;\n",
    "2. train our models and make predictions;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Load Data\n",
    "Let's start by loading the time series of the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('data/wwwusage.csv', names=['value'], header=0)\n",
    "y = df.value\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This abstract time serie does not seem seasonal, but with some increasing trend and somehow \"sticky\" (i.e. with some auto-regressivity). So it may be a good candidate for Auto-Regresive Moving Average (ARIMA) models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build ARIMA model\n",
    "We will try to forecast the data thanks to ARIMA models (Auto Regressive Integrated Moving Average).\n",
    "\n",
    "For that, we will need to :\n",
    "1. find how to stationarize the time serie (I in SARIMA)\n",
    "2. find the auto-regressive (AR) part\n",
    "3. find the Moving-Average (MA) part\n",
    "4. Fit\n",
    "5. Assess performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Ensure stationarity\n",
    "\n",
    "ARIMA models applies to \"stationary\" time series only.\n",
    "\n",
    "üëâ Check its stationarity precisely using the [`Augmented Dick Fuller test`](https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.adfuller.html), and especially its p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value should be  less than 0.05 to have a 95% confidence in the stationarity.  \n",
    "If the p-value is larger than 0.05, we cannot reject the null hypothesis (null hypothesis = \"the process is not stationary\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the time series is not stationary, it needs to be stationarized through **differencing**. \n",
    "- It means that we take the difference between each value and the preceding one (*first difference*).\n",
    "- Repeat process on the differentiated serie if you want the *second difference*, etc...\n",
    "\n",
    "üëâ Find the minimum order of differencing we need to make it stationnary (plot the curves to visualize them, and print their adfuller p-value to be sure)\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "`pd.Series.diff`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a close-call here between one and two diff orders. Differentiating too much a time series may also reduce performance of your ARIMA models. Let's have a closer look:\n",
    "\n",
    "üëâ Plot autocorrelation plot ([`plot_acf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html)) for diff order 1 and 2.\n",
    "\n",
    "(üí°Pro tip: Avoid duplicating statsmodels plots by calling `plt.show()` or by adding `;` to the end of each instantiation of a statsmodels plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our \"second order diff\" autocorrelation plot, the lag coefficient n¬∞1 is close to 0, while the second one escapes far into negative territory. This might indicate we have over-differentiated the series. (Remember: we never care about the lag n¬∞0 which is always equal to 1)\n",
    "\n",
    "üëâ Let's (temptatively) keep only one diff order and name this series `y_diff` (we can always try more diff later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just found the term \"I\" in ARIMA: `d = 1` for 1-diff before stationary (I refers to \"integration\", \"d\" for differentiation...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Select AR order (p) and MA order (q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MA($\\color{blue}{q}$) = number of lag beyond which the $\\color{blue}{ACF}$ of  $Y^{\\color{green}{(d)}}$ cuts off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MA order (`q`) can be found by looking at the autocorrelation plot ([`plot_acf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html)) applied to`y_diff`. \n",
    "\n",
    "üëâ determine `q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could choose q = 4, but it's more conservatively to try with `q=2` to start with.\n",
    "\n",
    "When in doubt, go with the simpler model that sufficiently explains the Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR($\\color{red}{p}$) = number of lags beyond which the $\\color{red}{PACF}$ of $Y^{\\color{green}{(d)}}$  cuts off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR order (`p`) can be found by investigating the **p**artial autocorrelation plot [`plot_pacf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_pacf.html) applied to `y_diff`.\n",
    "\n",
    "(Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series)\n",
    "\n",
    "üëâ Determine `p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could choose `p = 3` as the first 3 lag terms seems above the significance level, but we could also go with a simpler model `p = 1`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Build the model\n",
    "\n",
    "Now that you have chosen the values for `p`, ` d` and `q` for the ARIMA, \n",
    "\n",
    "üëâ build the `arima_model` from `statsmodels`.\n",
    "- fit the the model\n",
    "- print the model (`.summary`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è If your p-values are too high, try remove these terms by reducing the corresponding AR or SA coefficients.\n",
    "\n",
    "You can evaluate overall performance of your fit by minimizing the [`AIC - akaike information criterion`](https://towardsdatascience.com/the-akaike-information-criterion-c20c8fd832f2) value\n",
    "\n",
    "It seems that the (1,1,1) ARIMA models have less chance of overfitting (p-values remains low) and maintain a quasi similar AIC score than other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Visualize your model predictions with `.plot_predict()`\n",
    "\n",
    "- Look closely at the method default params, especially `dynamic`. \n",
    "- Do you think your model would have such good performance in reality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è `dynamic=False` actually makes use of all available values `y` in order to predict `y_pred`, making your ARIMA prediction use up to $y_{t-1}$ to predict $y_t$. In reality, you don't have access to all `y`, especially if you want to predict several intervals in the future.\n",
    "\n",
    "üëâ Try to use `dynamic=True` to plot a prection of the _last 15 values_ in a situation where the model only have _access to data up to 85_. That is to say, the model:\n",
    "- predicts 86 based on true [1...85]\n",
    "- then predicts 87 based on [1...85] _plus_ it's previouly predicted value for 86\n",
    "- etc...iteratively until 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è That's still not a _true_ forecast!! Why??\n",
    "\n",
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "Our model has \"seen\" the whole `y_true` serie during the fitting phase!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Out-of-sample forecasts (real \"future\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Create a train-test-split keep the last 15 datapoints only for the test set, and train your ARIMA on the train set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We are \"now\" in step 85 and have never seen the future:\n",
    "- Use `.forecast()` method on your fitted model to \"forecast\" the 15 next datapoints (i.e beyond the end of your train dataset) \n",
    "- Plot forecasted values as well as the higher and lower range of 95% uncertainty interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Try to also plot your previous 85 `y` real datapoints to better grasp model performance relative to the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Can you trust your 95% confidence interval? (conditions for inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Plot the residuals `model.resid` to ensure there are no patterns\n",
    "- Normally distributed\n",
    "- Mean zero\n",
    "- Uniform variance\n",
    "- No autoregressive patterns (you can plot_acf the residuals if you really want)\n",
    "\n",
    "Note: residuals are constructed by 'seing' all data as in `plot_predict(dynamic=False)`\n",
    "\n",
    "Also try to plot a histogram or kde fit of the residuals to see if they are approximately normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Cross-validated performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Below are the given the most common performance metrics for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import acf\n",
    "def forecast_accuracy(y_pred: pd.Series, y_true: pd.Series) -> float:\n",
    "    \n",
    "    mape = np.mean(np.abs(y_pred - y_true)/np.abs(y_true))  # Mean Absolute Percentage Error\n",
    "    me = np.mean(y_pred - y_true)             # ME\n",
    "    mae = np.mean(np.abs(y_pred - y_true))    # MAE\n",
    "    mpe = np.mean((y_pred - y_true)/y_true)   # MPE\n",
    "    rmse = np.mean((y_pred - y_true)**2)**.5  # RMSE\n",
    "    corr = np.corrcoef(y_pred, y_true)[0,1]   # Correlation between the Actual and the Forecast\n",
    "    mins = np.amin(np.hstack([y_pred.values.reshape(-1,1), y_true.values.reshape(-1,1)]), axis=1)\n",
    "    maxs = np.amax(np.hstack([y_pred.values.reshape(-1,1), y_true.values.reshape(-1,1)]), axis=1)\n",
    "    minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    acf1 = acf(y_pred-y_true, fft=False)[1]                      # Lag 1 Autocorrelation of Error\n",
    "    return({'mape':mape, 'me':me, 'mae': mae, \n",
    "            'mpe': mpe, 'rmse':rmse, 'acf1':acf1, \n",
    "            'corr':corr, 'minmax':minmax})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Play with you ARIMA hyper-parameters and see the impact on your forecast performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run your own gridsearch for (p,d,q) using `pmdarima`. Use at least\n",
    "- `trace=True`\n",
    "- `error_action='ignore'`\n",
    "- `suppress_warnings=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Cross-validate performance of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, Results and GridSearch should always be cross validated: \n",
    "\n",
    "Feel free to use [`sklearn.TimeSeriesSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) to create continguous K-folds so as to truely evaluate the performance of your model and find the best hyper-params after cross validation\n",
    "\n",
    "<img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0101.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}