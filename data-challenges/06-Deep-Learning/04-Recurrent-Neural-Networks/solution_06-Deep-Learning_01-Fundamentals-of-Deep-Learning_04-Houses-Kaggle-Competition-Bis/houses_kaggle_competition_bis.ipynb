{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Houses Kaggle Competition (bis üî•) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src='https://github.com/lewagon/data-images/blob/master/ML/kaggle-batch-challenge.png?raw=true' width=600>](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "Let's re-use our previous pipeline build in module `05-07-Ensemble-Methods` and improve final predictions using a Neural Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-use already-built preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load our training dataset\n",
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv\")\n",
    "X = data.drop(columns='SalePrice')\n",
    "y = data['SalePrice']\n",
    "\n",
    "# You don't have access to y_yest! Only Kaggle has it.\n",
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n",
    "\n",
    "print(X.shape, y.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find in `utils/preprocessor.py` the data-preprocessing pipeline that was built in our previous iteration.\n",
    "\n",
    "‚ùì Run the cell below, and make sure you understand what the pipeline does. Look at the code in `preprocessor.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessor import create_preproc\n",
    "preproc = create_preproc(X)\n",
    "preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Fit the preprocessor you your train set and create your feature matrix `X_preproc` that will be used by the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your prediction in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your first **regression** task with Keras! \n",
    "- The cell below contains compiler and fit hyper-parameters we recommend you to start with.\n",
    "- Kaggle's [rule](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) requires to minimize `rmsle` (Root Mean Square Log Error). As you can see, we have been able to specify `msle` direcly as loss-function with Keras! Just remember to take square-root of your loss results to read your rmsle metric.\n",
    "- The best boosted-tree `rmsle` score to beat is around **0.13**\n",
    "\n",
    "‚ùì **Question** ‚ùì\n",
    "- Your responsibility is to build the best model architecture, and to control the epoch number to avoid overfitting.\n",
    "- We recommand you to create a train/val split upfront to visually control the validation loss thanks to `plot_history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train-val split here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "\n",
    "    ### YOUR MODEL ARCHITECTURE HERE\n",
    "    # model = ...\n",
    "\n",
    "    \n",
    "    # Recommended compilator\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='msle', # directly optimize for the squared log error!\n",
    "    return model\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=100, # Play with this until your validation loss overfit\n",
    "                    batch_size=16, # Keep batch size to 16 today\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(np.sqrt(history.history['loss']))\n",
    "    plt.plot(np.sqrt(history.history['val_loss']))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('MSLE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì\n",
    "- Are you satisfied with your score?\n",
    "- Before you publish it, ask yourself if you can trust it entirely? Has it been cross-validated? \n",
    "- Feel free to cross-validate it manually with a for loop in python if you want before submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÖFINAL SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the house prices of your test set and submit results to kaggle! Be carefull with the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}