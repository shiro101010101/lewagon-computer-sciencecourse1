{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7TpZ5ucrRtu"
   },
   "source": [
    "# Finetune your Neural Network\n",
    "\n",
    "**Exercise objectives:**\n",
    "- `Finetune` the model optimizer\n",
    "- `Save` and `Load` a `trained neural network`\n",
    "\n",
    "<hr>\n",
    "\n",
    "Now that you have solid foundations of what Neural Networks, how to design their architecture and how to regularize them, let's take a closer look at the `.compile(loss = ..., metrics = ..., activation = ...)` part.\n",
    "\n",
    "# Data\n",
    "\n",
    "We will use the data from the `Boston Housing dataset`. \n",
    "\n",
    "Our goal is to `predict the values of the houses` (in k USD), and we will measure our models' performances  using the `Mean Absolute Error` metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "SW7WhiHYrRtw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "HUO_GKc_rRtz",
    "outputId": "1683236d-b9c7-4fb5-d441-aba7ae7abd24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f52b94fa410>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "X_train.shape\n",
    "\n",
    "sns.histplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XU6nRg4rRt0",
    "outputId": "000e7aa5-3933-4771-8f35-52fb2e3e04c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       404 non-null    float64\n",
      " 1   1       404 non-null    float64\n",
      " 2   2       404 non-null    float64\n",
      " 3   3       404 non-null    float64\n",
      " 4   4       404 non-null    float64\n",
      " 5   5       404 non-null    float64\n",
      " 6   6       404 non-null    float64\n",
      " 7   7       404 non-null    float64\n",
      " 8   8       404 non-null    float64\n",
      " 9   9       404 non-null    float64\n",
      " 10  10      404 non-null    float64\n",
      " 11  11      404 non-null    float64\n",
      " 12  12      404 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 41.2 KB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(X_train).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "oA-RrQJPrRt0",
    "outputId": "45ca5732-09ab-4687-b089-ed83388a9d5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8f4bd263-3784-4965-99e6-a5e83091a1ab\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.745111</td>\n",
       "      <td>11.480198</td>\n",
       "      <td>11.104431</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.557356</td>\n",
       "      <td>6.267082</td>\n",
       "      <td>69.010644</td>\n",
       "      <td>3.740271</td>\n",
       "      <td>9.440594</td>\n",
       "      <td>405.898515</td>\n",
       "      <td>18.475990</td>\n",
       "      <td>354.783168</td>\n",
       "      <td>12.740817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.240734</td>\n",
       "      <td>23.767711</td>\n",
       "      <td>6.811308</td>\n",
       "      <td>0.241238</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.709788</td>\n",
       "      <td>27.940665</td>\n",
       "      <td>2.030215</td>\n",
       "      <td>8.698360</td>\n",
       "      <td>166.374543</td>\n",
       "      <td>2.200382</td>\n",
       "      <td>94.111148</td>\n",
       "      <td>7.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.874750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.077100</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.225000</td>\n",
       "      <td>374.672500</td>\n",
       "      <td>6.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.268880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.198500</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>3.142300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>11.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.674808</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.609000</td>\n",
       "      <td>94.100000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.157500</td>\n",
       "      <td>17.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f4bd263-3784-4965-99e6-a5e83091a1ab')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8f4bd263-3784-4965-99e6-a5e83091a1ab button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8f4bd263-3784-4965-99e6-a5e83091a1ab');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               0           1           2   ...          10          11          12\n",
       "count  404.000000  404.000000  404.000000  ...  404.000000  404.000000  404.000000\n",
       "mean     3.745111   11.480198   11.104431  ...   18.475990  354.783168   12.740817\n",
       "std      9.240734   23.767711    6.811308  ...    2.200382   94.111148    7.254545\n",
       "min      0.006320    0.000000    0.460000  ...   12.600000    0.320000    1.730000\n",
       "25%      0.081437    0.000000    5.130000  ...   17.225000  374.672500    6.890000\n",
       "50%      0.268880    0.000000    9.690000  ...   19.100000  391.250000   11.395000\n",
       "75%      3.674808   12.500000   18.100000  ...   20.200000  396.157500   17.092500\n",
       "max     88.976200  100.000000   27.740000  ...   22.000000  396.900000   37.970000\n",
       "\n",
       "[8 rows x 13 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8sUMhTerRt0"
   },
   "source": [
    "❓ **Question** ❓ Standardize `X_train` and `X_test` set without data leakage, and replace them keeping similar variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "EBjdVl9krRt1",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sscaler=StandardScaler()\n",
    "\n",
    "sscaler.fit(X_train)\n",
    "S_X_train=sscaler.transform(X_train)\n",
    "S_X_test=sscaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzboxs7nrRt1"
   },
   "source": [
    "❓ **Question** ❓ To get a sense of a benchmark score you have to beat, what is the mean absolute error on the test set if your dumb prediction corresponds to the mean value of $y$ computed on the train set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aspm4ncnrRt2",
    "outputId": "33ca3df9-8d86-4245-f8cb-a0fc38153700",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.344205445544553\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg=RandomForestRegressor()\n",
    "\n",
    "reg.fit(S_X_train,y_train)\n",
    "y_pred=reg.predict(X_train)\n",
    "print('MAE:',metrics.mean_absolute_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDnox53IrRt2"
   },
   "source": [
    "# 1. The model\n",
    "\n",
    "❓ **Question** ❓ Now, write a function `initialize_model` that generates a neural network with 3 layers: \n",
    "- a layer with 10 neurons and the `relu` activation function (choose the appropriate input dimension)\n",
    "- a layer with 7 neurons and the `relu` activation function\n",
    "- an appropriate layer corresponding to the problem at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "H9p3_iJZrRt2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers, Sequential, layers\n",
    "\n",
    "\n",
    "model= Sequential()\n",
    "\n",
    "def initialize_model():\n",
    "  model= Sequential()\n",
    "  model.add(layers.Dense(10, activation='relu', input_dim=13))\n",
    "  model.add(layers.Dense(7, activation='relu'))\n",
    "  model.add(layers.Dense(1, activation='linear'))\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE2frzX8rRt3"
   },
   "source": [
    "# 2. The optimizer\n",
    "\n",
    "❓ **Question** ❓ Write a function that :\n",
    "* takes as arguments a model and an optimizer, \n",
    "* `compiles` the model,\n",
    "* and returns the compiled model\n",
    "\n",
    "Please select the `loss function` to be optimized and  the `metrics` on which the model should be evaluated wisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "Ph7bWcA_5t6h"
   },
   "outputs": [],
   "source": [
    "# REGRESSION\n",
    "# model= Sequential()\n",
    "# model.compile(loss='mse', \n",
    "#               optimizer='adam', \n",
    "#               metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "8V4OEE-brRt3"
   },
   "outputs": [],
   "source": [
    "#Please select the loss function to be optimized\n",
    "# and the metrics on which the model should be evaluated wisely.\n",
    "\n",
    "def compile_model(model, optimizer_name):\n",
    "  #best metrics\n",
    "  model.compile(loss=\"mse\",optimizer=optimizer_name,metrics=[\"mae\",\"mse\"])\n",
    "  return model\n",
    "\n",
    "\n",
    "#Please select the best loss function??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIJKHcks_MMF",
    "outputId": "70a6d045-8fbd-4af0-85c7-1154e0ac2f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HK_UjIEArRt3"
   },
   "source": [
    "❓ **Question** ❓ Initialize the model, compile it with the `adam` optimizer and fit it on the data. \n",
    "- Evaluate your model using an Early Stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NN6dgKVKrRt3",
    "outputId": "660ac857-13d2-47af-a925-de3c98337391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 567.6808 - mae: 22.1823 - mse: 567.6808 - val_loss: 655.8975 - val_mae: 23.4772 - val_mse: 655.8975\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 556.8536 - mae: 21.9554 - mse: 556.8536 - val_loss: 644.8503 - val_mae: 23.2504 - val_mse: 644.8503\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 546.1284 - mae: 21.7281 - mse: 546.1284 - val_loss: 633.5009 - val_mae: 23.0172 - val_mse: 633.5009\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 534.4510 - mae: 21.4858 - mse: 534.4510 - val_loss: 621.4348 - val_mae: 22.7697 - val_mse: 621.4348\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 521.4531 - mae: 21.2076 - mse: 521.4531 - val_loss: 606.8545 - val_mae: 22.4700 - val_mse: 606.8545\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 506.4302 - mae: 20.8803 - mse: 506.4302 - val_loss: 589.1158 - val_mae: 22.0995 - val_mse: 589.1158\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 487.9366 - mae: 20.4693 - mse: 487.9366 - val_loss: 569.0235 - val_mae: 21.6651 - val_mse: 569.0235\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 466.6265 - mae: 19.9782 - mse: 466.6265 - val_loss: 544.5452 - val_mae: 21.1179 - val_mse: 544.5452\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 440.7783 - mae: 19.3685 - mse: 440.7783 - val_loss: 514.4562 - val_mae: 20.4148 - val_mse: 514.4562\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 408.0995 - mae: 18.5707 - mse: 408.0995 - val_loss: 477.7551 - val_mae: 19.5200 - val_mse: 477.7551\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 369.1920 - mae: 17.5575 - mse: 369.1920 - val_loss: 433.8562 - val_mae: 18.3679 - val_mse: 433.8562\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 324.7833 - mae: 16.3191 - mse: 324.7833 - val_loss: 388.5837 - val_mae: 17.0589 - val_mse: 388.5837\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 280.8649 - mae: 14.9454 - mse: 280.8649 - val_loss: 343.4971 - val_mae: 15.5944 - val_mse: 343.4971\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 238.8145 - mae: 13.4734 - mse: 238.8145 - val_loss: 301.5013 - val_mae: 14.0485 - val_mse: 301.5013\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 202.1838 - mae: 11.9920 - mse: 202.1838 - val_loss: 263.8567 - val_mae: 12.5781 - val_mse: 263.8567\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 171.0276 - mae: 10.6781 - mse: 171.0276 - val_loss: 233.1721 - val_mae: 11.4373 - val_mse: 233.1721\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 146.0390 - mae: 9.5927 - mse: 146.0390 - val_loss: 209.9409 - val_mae: 10.7411 - val_mse: 209.9409\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 127.7638 - mae: 8.8013 - mse: 127.7638 - val_loss: 189.6750 - val_mae: 10.1860 - val_mse: 189.6750\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 112.4520 - mae: 8.1855 - mse: 112.4520 - val_loss: 173.2748 - val_mae: 9.7109 - val_mse: 173.2748\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 100.7467 - mae: 7.6981 - mse: 100.7467 - val_loss: 157.6718 - val_mae: 9.2707 - val_mse: 157.6718\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 89.7079 - mae: 7.2105 - mse: 89.7079 - val_loss: 144.4178 - val_mae: 8.8461 - val_mse: 144.4178\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 80.5524 - mae: 6.7659 - mse: 80.5524 - val_loss: 132.5648 - val_mae: 8.4357 - val_mse: 132.5648\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 72.4737 - mae: 6.3820 - mse: 72.4737 - val_loss: 122.1031 - val_mae: 8.0457 - val_mse: 122.1031\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 65.7777 - mae: 6.0221 - mse: 65.7777 - val_loss: 112.4183 - val_mae: 7.6904 - val_mse: 112.4183\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 59.5664 - mae: 5.6782 - mse: 59.5664 - val_loss: 104.6976 - val_mae: 7.3449 - val_mse: 104.6976\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 54.6938 - mae: 5.3913 - mse: 54.6938 - val_loss: 97.2499 - val_mae: 7.0357 - val_mse: 97.2499\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 50.4030 - mae: 5.1499 - mse: 50.4030 - val_loss: 91.1582 - val_mae: 6.7873 - val_mse: 91.1582\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 47.1262 - mae: 4.9341 - mse: 47.1262 - val_loss: 85.6018 - val_mae: 6.5467 - val_mse: 85.6018\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 44.0446 - mae: 4.7491 - mse: 44.0446 - val_loss: 81.2175 - val_mae: 6.3415 - val_mse: 81.2175\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.8506 - mae: 4.5981 - mse: 41.8506 - val_loss: 76.5704 - val_mae: 6.1373 - val_mse: 76.5704\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39.4781 - mae: 4.4636 - mse: 39.4781 - val_loss: 72.7321 - val_mae: 5.9864 - val_mse: 72.7321\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.6035 - mae: 4.3463 - mse: 37.6035 - val_loss: 69.2223 - val_mae: 5.8355 - val_mse: 69.2223\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 36.0241 - mae: 4.2521 - mse: 36.0241 - val_loss: 65.7921 - val_mae: 5.7062 - val_mse: 65.7921\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 34.3925 - mae: 4.1471 - mse: 34.3925 - val_loss: 63.2683 - val_mae: 5.5939 - val_mse: 63.2683\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 33.1308 - mae: 4.0672 - mse: 33.1308 - val_loss: 60.5723 - val_mae: 5.4697 - val_mse: 60.5723\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 31.9459 - mae: 3.9848 - mse: 31.9459 - val_loss: 58.2191 - val_mae: 5.3529 - val_mse: 58.2191\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 30.8233 - mae: 3.9123 - mse: 30.8233 - val_loss: 56.6056 - val_mae: 5.2668 - val_mse: 56.6056\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.8747 - mae: 3.8537 - mse: 29.8747 - val_loss: 54.6408 - val_mae: 5.1829 - val_mse: 54.6408\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.0615 - mae: 3.8141 - mse: 29.0615 - val_loss: 52.6971 - val_mae: 5.1026 - val_mse: 52.6971\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 28.0407 - mae: 3.7509 - mse: 28.0407 - val_loss: 51.3135 - val_mae: 5.0268 - val_mse: 51.3135\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.2598 - mae: 3.6908 - mse: 27.2598 - val_loss: 49.5764 - val_mae: 4.9364 - val_mse: 49.5764\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 26.4626 - mae: 3.6436 - mse: 26.4626 - val_loss: 48.0753 - val_mae: 4.8563 - val_mse: 48.0753\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.8326 - mae: 3.6042 - mse: 25.8326 - val_loss: 46.7057 - val_mae: 4.7775 - val_mse: 46.7057\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 25.0764 - mae: 3.5614 - mse: 25.0764 - val_loss: 45.4454 - val_mae: 4.7208 - val_mse: 45.4454\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 24.4759 - mae: 3.5198 - mse: 24.4759 - val_loss: 44.4963 - val_mae: 4.6526 - val_mse: 44.4963\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.8585 - mae: 3.4766 - mse: 23.8585 - val_loss: 43.2981 - val_mae: 4.5770 - val_mse: 43.2981\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 23.3422 - mae: 3.4376 - mse: 23.3422 - val_loss: 42.1212 - val_mae: 4.5235 - val_mse: 42.1212\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.7319 - mae: 3.4104 - mse: 22.7319 - val_loss: 41.0990 - val_mae: 4.4894 - val_mse: 41.0990\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.2302 - mae: 3.3804 - mse: 22.2302 - val_loss: 40.0865 - val_mae: 4.4209 - val_mse: 40.0865\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 21.7080 - mae: 3.3347 - mse: 21.7080 - val_loss: 39.4197 - val_mae: 4.3585 - val_mse: 39.4197\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 21.2777 - mae: 3.3099 - mse: 21.2777 - val_loss: 38.4256 - val_mae: 4.3151 - val_mse: 38.4256\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.7359 - mae: 3.2736 - mse: 20.7359 - val_loss: 37.7092 - val_mae: 4.2624 - val_mse: 37.7092\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 20.3121 - mae: 3.2420 - mse: 20.3121 - val_loss: 37.0644 - val_mae: 4.2175 - val_mse: 37.0644\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.8539 - mae: 3.2158 - mse: 19.8539 - val_loss: 36.2503 - val_mae: 4.1762 - val_mse: 36.2503\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.4785 - mae: 3.1926 - mse: 19.4785 - val_loss: 35.4757 - val_mae: 4.1252 - val_mse: 35.4757\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 19.0938 - mae: 3.1770 - mse: 19.0938 - val_loss: 34.7624 - val_mae: 4.0914 - val_mse: 34.7624\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 18.6302 - mae: 3.1419 - mse: 18.6302 - val_loss: 34.3000 - val_mae: 4.0460 - val_mse: 34.3000\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 18.2785 - mae: 3.1088 - mse: 18.2785 - val_loss: 33.8701 - val_mae: 4.0095 - val_mse: 33.8701\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 17.9338 - mae: 3.0804 - mse: 17.9338 - val_loss: 33.2910 - val_mae: 3.9687 - val_mse: 33.2910\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 17.6374 - mae: 3.0593 - mse: 17.6374 - val_loss: 32.5906 - val_mae: 3.9187 - val_mse: 32.5906\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 17.3181 - mae: 3.0351 - mse: 17.3181 - val_loss: 32.1758 - val_mae: 3.8830 - val_mse: 32.1758\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 16.9917 - mae: 3.0095 - mse: 16.9917 - val_loss: 31.7523 - val_mae: 3.8499 - val_mse: 31.7523\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 16.6510 - mae: 2.9800 - mse: 16.6510 - val_loss: 31.3762 - val_mae: 3.8075 - val_mse: 31.3762\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 16.3789 - mae: 2.9514 - mse: 16.3789 - val_loss: 31.0199 - val_mae: 3.7738 - val_mse: 31.0199\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 16.1129 - mae: 2.9326 - mse: 16.1129 - val_loss: 30.4898 - val_mae: 3.7494 - val_mse: 30.4898\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 15.8370 - mae: 2.9090 - mse: 15.8370 - val_loss: 30.2217 - val_mae: 3.7204 - val_mse: 30.2217\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 15.5467 - mae: 2.8891 - mse: 15.5467 - val_loss: 29.8384 - val_mae: 3.7040 - val_mse: 29.8384\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 15.3029 - mae: 2.8666 - mse: 15.3029 - val_loss: 29.3674 - val_mae: 3.6545 - val_mse: 29.3674\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 15.0846 - mae: 2.8510 - mse: 15.0846 - val_loss: 29.0002 - val_mae: 3.6484 - val_mse: 29.0002\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 14.8189 - mae: 2.8250 - mse: 14.8189 - val_loss: 28.8061 - val_mae: 3.6117 - val_mse: 28.8061\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 14.6045 - mae: 2.7960 - mse: 14.6045 - val_loss: 28.4823 - val_mae: 3.5824 - val_mse: 28.4823\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 14.3504 - mae: 2.7780 - mse: 14.3504 - val_loss: 28.1787 - val_mae: 3.5647 - val_mse: 28.1787\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 14.1224 - mae: 2.7594 - mse: 14.1224 - val_loss: 27.8140 - val_mae: 3.5354 - val_mse: 27.8140\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 13.9352 - mae: 2.7405 - mse: 13.9352 - val_loss: 27.5087 - val_mae: 3.5087 - val_mse: 27.5087\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 13.7533 - mae: 2.7389 - mse: 13.7533 - val_loss: 27.2157 - val_mae: 3.5069 - val_mse: 27.2157\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 13.5317 - mae: 2.7141 - mse: 13.5317 - val_loss: 26.9064 - val_mae: 3.4662 - val_mse: 26.9064\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 13.3215 - mae: 2.6881 - mse: 13.3215 - val_loss: 26.7210 - val_mae: 3.4484 - val_mse: 26.7210\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 13.1436 - mae: 2.6711 - mse: 13.1436 - val_loss: 26.5147 - val_mae: 3.4233 - val_mse: 26.5147\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 12.9280 - mae: 2.6497 - mse: 12.9280 - val_loss: 26.1821 - val_mae: 3.4103 - val_mse: 26.1821\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.8309 - mae: 2.6467 - mse: 12.8309 - val_loss: 25.8885 - val_mae: 3.4165 - val_mse: 25.8885\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 12.6033 - mae: 2.6275 - mse: 12.6033 - val_loss: 25.7283 - val_mae: 3.3794 - val_mse: 25.7283\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 12.3720 - mae: 2.5967 - mse: 12.3720 - val_loss: 25.5567 - val_mae: 3.3814 - val_mse: 25.5567\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 12.2612 - mae: 2.5810 - mse: 12.2612 - val_loss: 25.3901 - val_mae: 3.3518 - val_mse: 25.3901\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 12.0917 - mae: 2.5683 - mse: 12.0917 - val_loss: 25.0417 - val_mae: 3.3366 - val_mse: 25.0417\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.9289 - mae: 2.5604 - mse: 11.9289 - val_loss: 24.8970 - val_mae: 3.3417 - val_mse: 24.8970\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.7939 - mae: 2.5336 - mse: 11.7939 - val_loss: 24.9164 - val_mae: 3.3056 - val_mse: 24.9164\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.6529 - mae: 2.5229 - mse: 11.6529 - val_loss: 24.6742 - val_mae: 3.3186 - val_mse: 24.6742\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.4294 - mae: 2.5040 - mse: 11.4294 - val_loss: 24.3960 - val_mae: 3.2862 - val_mse: 24.3960\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.2620 - mae: 2.4890 - mse: 11.2620 - val_loss: 24.2914 - val_mae: 3.2906 - val_mse: 24.2914\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.1056 - mae: 2.4652 - mse: 11.1056 - val_loss: 24.1844 - val_mae: 3.2811 - val_mse: 24.1844\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.9989 - mae: 2.4583 - mse: 10.9989 - val_loss: 24.0170 - val_mae: 3.2699 - val_mse: 24.0170\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.8353 - mae: 2.4412 - mse: 10.8353 - val_loss: 23.8402 - val_mae: 3.2524 - val_mse: 23.8402\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.7178 - mae: 2.4166 - mse: 10.7178 - val_loss: 23.8170 - val_mae: 3.2528 - val_mse: 23.8170\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.5851 - mae: 2.4057 - mse: 10.5851 - val_loss: 23.6460 - val_mae: 3.2282 - val_mse: 23.6460\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.4609 - mae: 2.3855 - mse: 10.4609 - val_loss: 23.5481 - val_mae: 3.2268 - val_mse: 23.5481\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10.3572 - mae: 2.3752 - mse: 10.3572 - val_loss: 23.3270 - val_mae: 3.2194 - val_mse: 23.3270\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.1753 - mae: 2.3534 - mse: 10.1753 - val_loss: 23.2965 - val_mae: 3.1877 - val_mse: 23.2965\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.0836 - mae: 2.3511 - mse: 10.0836 - val_loss: 23.1271 - val_mae: 3.1928 - val_mse: 23.1271\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.9816 - mae: 2.3388 - mse: 9.9816 - val_loss: 23.0798 - val_mae: 3.1860 - val_mse: 23.0798\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.8585 - mae: 2.3221 - mse: 9.8585 - val_loss: 22.9031 - val_mae: 3.1652 - val_mse: 22.9031\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.7562 - mae: 2.3163 - mse: 9.7562 - val_loss: 22.7983 - val_mae: 3.1616 - val_mse: 22.7983\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.6965 - mae: 2.3040 - mse: 9.6965 - val_loss: 22.7292 - val_mae: 3.1525 - val_mse: 22.7292\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.5820 - mae: 2.2919 - mse: 9.5820 - val_loss: 22.6306 - val_mae: 3.1253 - val_mse: 22.6306\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.4856 - mae: 2.2788 - mse: 9.4856 - val_loss: 22.4400 - val_mae: 3.1180 - val_mse: 22.4400\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.4231 - mae: 2.2737 - mse: 9.4231 - val_loss: 22.3340 - val_mae: 3.1355 - val_mse: 22.3340\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.3322 - mae: 2.2680 - mse: 9.3322 - val_loss: 22.3356 - val_mae: 3.1197 - val_mse: 22.3356\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.1821 - mae: 2.2485 - mse: 9.1821 - val_loss: 22.2528 - val_mae: 3.1005 - val_mse: 22.2528\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.1436 - mae: 2.2379 - mse: 9.1436 - val_loss: 22.0480 - val_mae: 3.0820 - val_mse: 22.0480\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.1038 - mae: 2.2393 - mse: 9.1038 - val_loss: 21.9416 - val_mae: 3.0979 - val_mse: 21.9416\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.9997 - mae: 2.2241 - mse: 8.9997 - val_loss: 21.8556 - val_mae: 3.0539 - val_mse: 21.8556\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.9024 - mae: 2.2195 - mse: 8.9024 - val_loss: 21.8506 - val_mae: 3.0837 - val_mse: 21.8506\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.7959 - mae: 2.2016 - mse: 8.7959 - val_loss: 21.6713 - val_mae: 3.0638 - val_mse: 21.6713\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.7395 - mae: 2.1948 - mse: 8.7395 - val_loss: 21.5239 - val_mae: 3.0212 - val_mse: 21.5239\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6518 - mae: 2.1844 - mse: 8.6518 - val_loss: 21.2943 - val_mae: 3.0272 - val_mse: 21.2943\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6098 - mae: 2.1801 - mse: 8.6098 - val_loss: 21.3374 - val_mae: 3.0336 - val_mse: 21.3374\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.5225 - mae: 2.1720 - mse: 8.5225 - val_loss: 21.0318 - val_mae: 2.9950 - val_mse: 21.0318\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.4710 - mae: 2.1648 - mse: 8.4710 - val_loss: 21.0286 - val_mae: 3.0122 - val_mse: 21.0286\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.3956 - mae: 2.1482 - mse: 8.3956 - val_loss: 21.0165 - val_mae: 2.9902 - val_mse: 21.0165\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.3056 - mae: 2.1430 - mse: 8.3056 - val_loss: 20.8608 - val_mae: 2.9809 - val_mse: 20.8608\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.2592 - mae: 2.1428 - mse: 8.2592 - val_loss: 20.7630 - val_mae: 2.9792 - val_mse: 20.7630\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.1987 - mae: 2.1372 - mse: 8.1987 - val_loss: 20.6839 - val_mae: 2.9752 - val_mse: 20.6839\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.1471 - mae: 2.1182 - mse: 8.1471 - val_loss: 20.6628 - val_mae: 2.9702 - val_mse: 20.6628\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.0437 - mae: 2.1138 - mse: 8.0437 - val_loss: 20.5389 - val_mae: 2.9504 - val_mse: 20.5389\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.0502 - mae: 2.1277 - mse: 8.0502 - val_loss: 20.4536 - val_mae: 2.9569 - val_mse: 20.4536\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9647 - mae: 2.1059 - mse: 7.9647 - val_loss: 20.3592 - val_mae: 2.9427 - val_mse: 20.3592\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.8913 - mae: 2.1010 - mse: 7.8913 - val_loss: 20.3324 - val_mae: 2.9337 - val_mse: 20.3324\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8326 - mae: 2.0999 - mse: 7.8326 - val_loss: 20.2945 - val_mae: 2.9371 - val_mse: 20.2945\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.8203 - mae: 2.0979 - mse: 7.8203 - val_loss: 20.3047 - val_mae: 2.9336 - val_mse: 20.3047\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7800 - mae: 2.0829 - mse: 7.7800 - val_loss: 20.1828 - val_mae: 2.9369 - val_mse: 20.1828\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.7053 - mae: 2.0783 - mse: 7.7053 - val_loss: 20.0446 - val_mae: 2.9115 - val_mse: 20.0446\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.6613 - mae: 2.0769 - mse: 7.6613 - val_loss: 20.0673 - val_mae: 2.9221 - val_mse: 20.0673\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.6026 - mae: 2.0703 - mse: 7.6026 - val_loss: 20.0211 - val_mae: 2.9213 - val_mse: 20.0211\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5883 - mae: 2.0664 - mse: 7.5883 - val_loss: 19.8232 - val_mae: 2.9022 - val_mse: 19.8232\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.5247 - mae: 2.0601 - mse: 7.5247 - val_loss: 19.8542 - val_mae: 2.9004 - val_mse: 19.8542\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4922 - mae: 2.0581 - mse: 7.4922 - val_loss: 19.8928 - val_mae: 2.9125 - val_mse: 19.8928\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4617 - mae: 2.0502 - mse: 7.4617 - val_loss: 19.8263 - val_mae: 2.8904 - val_mse: 19.8263\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4050 - mae: 2.0464 - mse: 7.4050 - val_loss: 19.8740 - val_mae: 2.9067 - val_mse: 19.8740\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3822 - mae: 2.0464 - mse: 7.3822 - val_loss: 19.7749 - val_mae: 2.8954 - val_mse: 19.7749\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3664 - mae: 2.0438 - mse: 7.3664 - val_loss: 19.7085 - val_mae: 2.8975 - val_mse: 19.7085\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3247 - mae: 2.0303 - mse: 7.3247 - val_loss: 19.6002 - val_mae: 2.8789 - val_mse: 19.6002\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2665 - mae: 2.0275 - mse: 7.2665 - val_loss: 19.5487 - val_mae: 2.8705 - val_mse: 19.5487\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2700 - mae: 2.0403 - mse: 7.2700 - val_loss: 19.5414 - val_mae: 2.8752 - val_mse: 19.5414\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2263 - mae: 2.0230 - mse: 7.2263 - val_loss: 19.5715 - val_mae: 2.8869 - val_mse: 19.5715\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1878 - mae: 2.0178 - mse: 7.1878 - val_loss: 19.5786 - val_mae: 2.8790 - val_mse: 19.5786\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1609 - mae: 2.0167 - mse: 7.1609 - val_loss: 19.5081 - val_mae: 2.8647 - val_mse: 19.5081\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1290 - mae: 2.0174 - mse: 7.1290 - val_loss: 19.4765 - val_mae: 2.8703 - val_mse: 19.4765\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0911 - mae: 2.0048 - mse: 7.0911 - val_loss: 19.4528 - val_mae: 2.8696 - val_mse: 19.4528\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0674 - mae: 2.0066 - mse: 7.0674 - val_loss: 19.4248 - val_mae: 2.8596 - val_mse: 19.4248\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0742 - mae: 2.0128 - mse: 7.0742 - val_loss: 19.4153 - val_mae: 2.8779 - val_mse: 19.4153\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0747 - mae: 2.0012 - mse: 7.0747 - val_loss: 19.4580 - val_mae: 2.8635 - val_mse: 19.4580\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0366 - mae: 2.0042 - mse: 7.0366 - val_loss: 19.3906 - val_mae: 2.8546 - val_mse: 19.3906\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9603 - mae: 1.9923 - mse: 6.9603 - val_loss: 19.3674 - val_mae: 2.8652 - val_mse: 19.3674\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9403 - mae: 1.9821 - mse: 6.9403 - val_loss: 19.3655 - val_mae: 2.8687 - val_mse: 19.3655\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9418 - mae: 1.9849 - mse: 6.9418 - val_loss: 19.3298 - val_mae: 2.8599 - val_mse: 19.3298\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9268 - mae: 1.9866 - mse: 6.9268 - val_loss: 19.3305 - val_mae: 2.8567 - val_mse: 19.3305\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8839 - mae: 1.9873 - mse: 6.8839 - val_loss: 19.3039 - val_mae: 2.8591 - val_mse: 19.3039\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8939 - mae: 1.9818 - mse: 6.8939 - val_loss: 19.2726 - val_mae: 2.8561 - val_mse: 19.2726\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8554 - mae: 1.9788 - mse: 6.8554 - val_loss: 19.2181 - val_mae: 2.8467 - val_mse: 19.2181\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8417 - mae: 1.9750 - mse: 6.8417 - val_loss: 19.1868 - val_mae: 2.8423 - val_mse: 19.1868\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8641 - mae: 1.9789 - mse: 6.8641 - val_loss: 19.1140 - val_mae: 2.8396 - val_mse: 19.1140\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7769 - mae: 1.9657 - mse: 6.7769 - val_loss: 19.1744 - val_mae: 2.8441 - val_mse: 19.1744\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7629 - mae: 1.9663 - mse: 6.7629 - val_loss: 19.1505 - val_mae: 2.8382 - val_mse: 19.1505\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7808 - mae: 1.9710 - mse: 6.7808 - val_loss: 19.1385 - val_mae: 2.8525 - val_mse: 19.1385\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7202 - mae: 1.9566 - mse: 6.7202 - val_loss: 19.0994 - val_mae: 2.8403 - val_mse: 19.0994\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6900 - mae: 1.9495 - mse: 6.6900 - val_loss: 19.1296 - val_mae: 2.8471 - val_mse: 19.1296\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6656 - mae: 1.9509 - mse: 6.6656 - val_loss: 19.1171 - val_mae: 2.8434 - val_mse: 19.1171\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6873 - mae: 1.9555 - mse: 6.6873 - val_loss: 19.1662 - val_mae: 2.8525 - val_mse: 19.1662\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6541 - mae: 1.9533 - mse: 6.6541 - val_loss: 19.1552 - val_mae: 2.8433 - val_mse: 19.1552\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6386 - mae: 1.9456 - mse: 6.6386 - val_loss: 19.0801 - val_mae: 2.8417 - val_mse: 19.0801\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6407 - mae: 1.9427 - mse: 6.6407 - val_loss: 19.0274 - val_mae: 2.8382 - val_mse: 19.0274\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6257 - mae: 1.9400 - mse: 6.6257 - val_loss: 19.0231 - val_mae: 2.8198 - val_mse: 19.0231\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6221 - mae: 1.9477 - mse: 6.6221 - val_loss: 18.9750 - val_mae: 2.8262 - val_mse: 18.9750\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5836 - mae: 1.9516 - mse: 6.5836 - val_loss: 19.0030 - val_mae: 2.8288 - val_mse: 19.0030\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5390 - mae: 1.9330 - mse: 6.5390 - val_loss: 19.0414 - val_mae: 2.8415 - val_mse: 19.0414\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5650 - mae: 1.9325 - mse: 6.5650 - val_loss: 19.0788 - val_mae: 2.8430 - val_mse: 19.0788\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5057 - mae: 1.9243 - mse: 6.5057 - val_loss: 18.9892 - val_mae: 2.8354 - val_mse: 18.9892\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5050 - mae: 1.9285 - mse: 6.5050 - val_loss: 18.9935 - val_mae: 2.8326 - val_mse: 18.9935\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5007 - mae: 1.9316 - mse: 6.5007 - val_loss: 18.9293 - val_mae: 2.8233 - val_mse: 18.9293\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4730 - mae: 1.9184 - mse: 6.4730 - val_loss: 18.9720 - val_mae: 2.8342 - val_mse: 18.9720\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4566 - mae: 1.9202 - mse: 6.4566 - val_loss: 18.9320 - val_mae: 2.8301 - val_mse: 18.9320\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4599 - mae: 1.9168 - mse: 6.4599 - val_loss: 18.7736 - val_mae: 2.8157 - val_mse: 18.7736\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4636 - mae: 1.9109 - mse: 6.4636 - val_loss: 18.7986 - val_mae: 2.8001 - val_mse: 18.7986\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4166 - mae: 1.9098 - mse: 6.4166 - val_loss: 18.9435 - val_mae: 2.8403 - val_mse: 18.9435\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3897 - mae: 1.9114 - mse: 6.3897 - val_loss: 18.9130 - val_mae: 2.8249 - val_mse: 18.9130\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4114 - mae: 1.9230 - mse: 6.4114 - val_loss: 18.9806 - val_mae: 2.8308 - val_mse: 18.9806\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3550 - mae: 1.9036 - mse: 6.3550 - val_loss: 18.7889 - val_mae: 2.8191 - val_mse: 18.7889\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3635 - mae: 1.9099 - mse: 6.3635 - val_loss: 18.8435 - val_mae: 2.8214 - val_mse: 18.8435\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3403 - mae: 1.9017 - mse: 6.3403 - val_loss: 18.7015 - val_mae: 2.8073 - val_mse: 18.7015\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3174 - mae: 1.8991 - mse: 6.3174 - val_loss: 18.7998 - val_mae: 2.8223 - val_mse: 18.7998\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2955 - mae: 1.8945 - mse: 6.2955 - val_loss: 18.8025 - val_mae: 2.8213 - val_mse: 18.8025\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3171 - mae: 1.8919 - mse: 6.3171 - val_loss: 18.7143 - val_mae: 2.8129 - val_mse: 18.7143\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2899 - mae: 1.8897 - mse: 6.2899 - val_loss: 18.7363 - val_mae: 2.8179 - val_mse: 18.7363\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2622 - mae: 1.8909 - mse: 6.2622 - val_loss: 18.7578 - val_mae: 2.8160 - val_mse: 18.7578\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3194 - mae: 1.9077 - mse: 6.3194 - val_loss: 18.7395 - val_mae: 2.8156 - val_mse: 18.7395\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2852 - mae: 1.8963 - mse: 6.2852 - val_loss: 18.7528 - val_mae: 2.8228 - val_mse: 18.7528\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2183 - mae: 1.8869 - mse: 6.2183 - val_loss: 18.7751 - val_mae: 2.8229 - val_mse: 18.7751\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2097 - mae: 1.8869 - mse: 6.2097 - val_loss: 18.7439 - val_mae: 2.8229 - val_mse: 18.7439\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2203 - mae: 1.8826 - mse: 6.2203 - val_loss: 18.7077 - val_mae: 2.8140 - val_mse: 18.7077\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1847 - mae: 1.8818 - mse: 6.1847 - val_loss: 18.6898 - val_mae: 2.8051 - val_mse: 18.6898\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2219 - mae: 1.8725 - mse: 6.2219 - val_loss: 18.6515 - val_mae: 2.8237 - val_mse: 18.6515\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1457 - mae: 1.8712 - mse: 6.1457 - val_loss: 18.7123 - val_mae: 2.8165 - val_mse: 18.7123\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1690 - mae: 1.8768 - mse: 6.1690 - val_loss: 18.6823 - val_mae: 2.8091 - val_mse: 18.6823\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1404 - mae: 1.8815 - mse: 6.1404 - val_loss: 18.7039 - val_mae: 2.8206 - val_mse: 18.7039\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1064 - mae: 1.8685 - mse: 6.1064 - val_loss: 18.7159 - val_mae: 2.8323 - val_mse: 18.7159\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0999 - mae: 1.8592 - mse: 6.0999 - val_loss: 18.6198 - val_mae: 2.8088 - val_mse: 18.6198\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1095 - mae: 1.8648 - mse: 6.1095 - val_loss: 18.6628 - val_mae: 2.8129 - val_mse: 18.6628\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0921 - mae: 1.8576 - mse: 6.0921 - val_loss: 18.6463 - val_mae: 2.8193 - val_mse: 18.6463\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0942 - mae: 1.8704 - mse: 6.0942 - val_loss: 18.6104 - val_mae: 2.8039 - val_mse: 18.6104\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0468 - mae: 1.8593 - mse: 6.0468 - val_loss: 18.6581 - val_mae: 2.8157 - val_mse: 18.6581\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0615 - mae: 1.8606 - mse: 6.0615 - val_loss: 18.6378 - val_mae: 2.8180 - val_mse: 18.6378\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0240 - mae: 1.8562 - mse: 6.0240 - val_loss: 18.6358 - val_mae: 2.8127 - val_mse: 18.6358\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0346 - mae: 1.8601 - mse: 6.0346 - val_loss: 18.6435 - val_mae: 2.8216 - val_mse: 18.6435\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0079 - mae: 1.8508 - mse: 6.0079 - val_loss: 18.5930 - val_mae: 2.8082 - val_mse: 18.5930\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9883 - mae: 1.8444 - mse: 5.9883 - val_loss: 18.6230 - val_mae: 2.8203 - val_mse: 18.6230\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9811 - mae: 1.8490 - mse: 5.9811 - val_loss: 18.6118 - val_mae: 2.8184 - val_mse: 18.6118\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0462 - mae: 1.8513 - mse: 6.0462 - val_loss: 18.6912 - val_mae: 2.8291 - val_mse: 18.6912\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0208 - mae: 1.8654 - mse: 6.0208 - val_loss: 18.5092 - val_mae: 2.8067 - val_mse: 18.5092\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9482 - mae: 1.8463 - mse: 5.9482 - val_loss: 18.5725 - val_mae: 2.8081 - val_mse: 18.5725\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9277 - mae: 1.8421 - mse: 5.9277 - val_loss: 18.5427 - val_mae: 2.8178 - val_mse: 18.5427\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9480 - mae: 1.8457 - mse: 5.9480 - val_loss: 18.5745 - val_mae: 2.8153 - val_mse: 18.5745\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9754 - mae: 1.8440 - mse: 5.9754 - val_loss: 18.5177 - val_mae: 2.8170 - val_mse: 18.5177\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9231 - mae: 1.8358 - mse: 5.9231 - val_loss: 18.4615 - val_mae: 2.7970 - val_mse: 18.4615\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9412 - mae: 1.8506 - mse: 5.9412 - val_loss: 18.5587 - val_mae: 2.8169 - val_mse: 18.5587\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9064 - mae: 1.8466 - mse: 5.9064 - val_loss: 18.5409 - val_mae: 2.8339 - val_mse: 18.5409\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9110 - mae: 1.8339 - mse: 5.9110 - val_loss: 18.4492 - val_mae: 2.8085 - val_mse: 18.4492\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9236 - mae: 1.8335 - mse: 5.9236 - val_loss: 18.4344 - val_mae: 2.7986 - val_mse: 18.4344\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8933 - mae: 1.8381 - mse: 5.8933 - val_loss: 18.5026 - val_mae: 2.8294 - val_mse: 18.5026\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9444 - mae: 1.8379 - mse: 5.9444 - val_loss: 18.5351 - val_mae: 2.8252 - val_mse: 18.5351\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.8410 - mae: 1.8333 - mse: 5.8410 - val_loss: 18.4750 - val_mae: 2.8139 - val_mse: 18.4750\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8739 - mae: 1.8307 - mse: 5.8739 - val_loss: 18.5258 - val_mae: 2.8226 - val_mse: 18.5258\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8137 - mae: 1.8270 - mse: 5.8137 - val_loss: 18.4971 - val_mae: 2.8215 - val_mse: 18.4971\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8463 - mae: 1.8419 - mse: 5.8463 - val_loss: 18.5031 - val_mae: 2.8304 - val_mse: 18.5031\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.8329 - mae: 1.8304 - mse: 5.8329 - val_loss: 18.4401 - val_mae: 2.8281 - val_mse: 18.4401\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7776 - mae: 1.8139 - mse: 5.7776 - val_loss: 18.4166 - val_mae: 2.8225 - val_mse: 18.4166\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8419 - mae: 1.8245 - mse: 5.8419 - val_loss: 18.3508 - val_mae: 2.8078 - val_mse: 18.3508\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7831 - mae: 1.8260 - mse: 5.7831 - val_loss: 18.4162 - val_mae: 2.8258 - val_mse: 18.4162\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7596 - mae: 1.8215 - mse: 5.7596 - val_loss: 18.4166 - val_mae: 2.8288 - val_mse: 18.4166\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7827 - mae: 1.8175 - mse: 5.7827 - val_loss: 18.2949 - val_mae: 2.8157 - val_mse: 18.2949\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7594 - mae: 1.8188 - mse: 5.7594 - val_loss: 18.4576 - val_mae: 2.8291 - val_mse: 18.4576\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7488 - mae: 1.8196 - mse: 5.7488 - val_loss: 18.3818 - val_mae: 2.8284 - val_mse: 18.3818\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7236 - mae: 1.8121 - mse: 5.7236 - val_loss: 18.3691 - val_mae: 2.8233 - val_mse: 18.3691\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7386 - mae: 1.8203 - mse: 5.7386 - val_loss: 18.3982 - val_mae: 2.8339 - val_mse: 18.3982\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7014 - mae: 1.8141 - mse: 5.7014 - val_loss: 18.3099 - val_mae: 2.8213 - val_mse: 18.3099\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7229 - mae: 1.8089 - mse: 5.7229 - val_loss: 18.2834 - val_mae: 2.8152 - val_mse: 18.2834\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6846 - mae: 1.8041 - mse: 5.6846 - val_loss: 18.2757 - val_mae: 2.8151 - val_mse: 18.2757\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7010 - mae: 1.8078 - mse: 5.7010 - val_loss: 18.4548 - val_mae: 2.8470 - val_mse: 18.4548\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7112 - mae: 1.8108 - mse: 5.7112 - val_loss: 18.3205 - val_mae: 2.8146 - val_mse: 18.3205\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6671 - mae: 1.8101 - mse: 5.6671 - val_loss: 18.4155 - val_mae: 2.8442 - val_mse: 18.4155\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6581 - mae: 1.8036 - mse: 5.6581 - val_loss: 18.3749 - val_mae: 2.8389 - val_mse: 18.3749\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.6551 - mae: 1.8045 - mse: 5.6551 - val_loss: 18.3492 - val_mae: 2.8317 - val_mse: 18.3492\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6690 - mae: 1.8062 - mse: 5.6690 - val_loss: 18.3712 - val_mae: 2.8413 - val_mse: 18.3712\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.6541 - mae: 1.7971 - mse: 5.6541 - val_loss: 18.2008 - val_mae: 2.8118 - val_mse: 18.2008\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6745 - mae: 1.8070 - mse: 5.6745 - val_loss: 18.3916 - val_mae: 2.8578 - val_mse: 18.3916\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6323 - mae: 1.8054 - mse: 5.6323 - val_loss: 18.2470 - val_mae: 2.8179 - val_mse: 18.2470\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5949 - mae: 1.7957 - mse: 5.5949 - val_loss: 18.3656 - val_mae: 2.8444 - val_mse: 18.3656\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5975 - mae: 1.7953 - mse: 5.5975 - val_loss: 18.2668 - val_mae: 2.8382 - val_mse: 18.2668\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5816 - mae: 1.7878 - mse: 5.5816 - val_loss: 18.2258 - val_mae: 2.8332 - val_mse: 18.2258\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5606 - mae: 1.7829 - mse: 5.5606 - val_loss: 18.2409 - val_mae: 2.8279 - val_mse: 18.2409\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5942 - mae: 1.7947 - mse: 5.5942 - val_loss: 18.2245 - val_mae: 2.8181 - val_mse: 18.2245\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5724 - mae: 1.7894 - mse: 5.5724 - val_loss: 18.2716 - val_mae: 2.8477 - val_mse: 18.2716\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5631 - mae: 1.7872 - mse: 5.5631 - val_loss: 18.2776 - val_mae: 2.8382 - val_mse: 18.2776\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5543 - mae: 1.7920 - mse: 5.5543 - val_loss: 18.2680 - val_mae: 2.8417 - val_mse: 18.2680\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5476 - mae: 1.7846 - mse: 5.5476 - val_loss: 18.2765 - val_mae: 2.8497 - val_mse: 18.2765\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5437 - mae: 1.7813 - mse: 5.5437 - val_loss: 18.1983 - val_mae: 2.8293 - val_mse: 18.1983\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5243 - mae: 1.7786 - mse: 5.5243 - val_loss: 18.2242 - val_mae: 2.8357 - val_mse: 18.2242\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5381 - mae: 1.7882 - mse: 5.5381 - val_loss: 18.1525 - val_mae: 2.8287 - val_mse: 18.1525\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5399 - mae: 1.7816 - mse: 5.5399 - val_loss: 18.2214 - val_mae: 2.8390 - val_mse: 18.2214\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4875 - mae: 1.7775 - mse: 5.4875 - val_loss: 18.1540 - val_mae: 2.8350 - val_mse: 18.1540\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4964 - mae: 1.7767 - mse: 5.4964 - val_loss: 18.1595 - val_mae: 2.8362 - val_mse: 18.1595\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4714 - mae: 1.7795 - mse: 5.4714 - val_loss: 18.2165 - val_mae: 2.8367 - val_mse: 18.2165\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4972 - mae: 1.7820 - mse: 5.4972 - val_loss: 18.2184 - val_mae: 2.8516 - val_mse: 18.2184\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4607 - mae: 1.7712 - mse: 5.4607 - val_loss: 18.1158 - val_mae: 2.8392 - val_mse: 18.1158\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4712 - mae: 1.7754 - mse: 5.4712 - val_loss: 18.1747 - val_mae: 2.8461 - val_mse: 18.1747\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4751 - mae: 1.7851 - mse: 5.4751 - val_loss: 18.0914 - val_mae: 2.8280 - val_mse: 18.0914\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4464 - mae: 1.7681 - mse: 5.4464 - val_loss: 18.1486 - val_mae: 2.8518 - val_mse: 18.1486\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4357 - mae: 1.7658 - mse: 5.4357 - val_loss: 18.0653 - val_mae: 2.8375 - val_mse: 18.0653\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4265 - mae: 1.7749 - mse: 5.4265 - val_loss: 18.1645 - val_mae: 2.8434 - val_mse: 18.1645\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4076 - mae: 1.7721 - mse: 5.4076 - val_loss: 18.0568 - val_mae: 2.8398 - val_mse: 18.0568\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4009 - mae: 1.7639 - mse: 5.4009 - val_loss: 18.0152 - val_mae: 2.8381 - val_mse: 18.0152\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3859 - mae: 1.7580 - mse: 5.3859 - val_loss: 17.9856 - val_mae: 2.8315 - val_mse: 17.9856\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4081 - mae: 1.7706 - mse: 5.4081 - val_loss: 18.0527 - val_mae: 2.8434 - val_mse: 18.0527\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4078 - mae: 1.7585 - mse: 5.4078 - val_loss: 18.0443 - val_mae: 2.8420 - val_mse: 18.0443\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3894 - mae: 1.7537 - mse: 5.3894 - val_loss: 18.0259 - val_mae: 2.8443 - val_mse: 18.0259\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3834 - mae: 1.7596 - mse: 5.3834 - val_loss: 18.0745 - val_mae: 2.8446 - val_mse: 18.0745\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3380 - mae: 1.7583 - mse: 5.3380 - val_loss: 18.0418 - val_mae: 2.8549 - val_mse: 18.0418\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.3465 - mae: 1.7594 - mse: 5.3465 - val_loss: 17.9670 - val_mae: 2.8389 - val_mse: 17.9670\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3364 - mae: 1.7530 - mse: 5.3364 - val_loss: 17.9502 - val_mae: 2.8338 - val_mse: 17.9502\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3161 - mae: 1.7571 - mse: 5.3161 - val_loss: 17.9958 - val_mae: 2.8429 - val_mse: 17.9958\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3259 - mae: 1.7618 - mse: 5.3259 - val_loss: 18.0724 - val_mae: 2.8544 - val_mse: 18.0724\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3000 - mae: 1.7457 - mse: 5.3000 - val_loss: 17.9727 - val_mae: 2.8515 - val_mse: 17.9727\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3730 - mae: 1.7586 - mse: 5.3730 - val_loss: 18.0411 - val_mae: 2.8658 - val_mse: 18.0411\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3091 - mae: 1.7569 - mse: 5.3091 - val_loss: 17.9909 - val_mae: 2.8290 - val_mse: 17.9909\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.2771 - mae: 1.7410 - mse: 5.2771 - val_loss: 17.9677 - val_mae: 2.8541 - val_mse: 17.9677\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.3266 - mae: 1.7630 - mse: 5.3266 - val_loss: 18.0124 - val_mae: 2.8586 - val_mse: 18.0124\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.2669 - mae: 1.7497 - mse: 5.2669 - val_loss: 17.9396 - val_mae: 2.8456 - val_mse: 17.9396\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.2886 - mae: 1.7533 - mse: 5.2886 - val_loss: 17.8894 - val_mae: 2.8321 - val_mse: 17.8894\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.2483 - mae: 1.7438 - mse: 5.2483 - val_loss: 17.9322 - val_mae: 2.8507 - val_mse: 17.9322\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3241 - mae: 1.7519 - mse: 5.3241 - val_loss: 17.8654 - val_mae: 2.8494 - val_mse: 17.8654\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2537 - mae: 1.7393 - mse: 5.2537 - val_loss: 18.0021 - val_mae: 2.8637 - val_mse: 18.0021\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2463 - mae: 1.7408 - mse: 5.2463 - val_loss: 17.9517 - val_mae: 2.8600 - val_mse: 17.9517\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.2320 - mae: 1.7452 - mse: 5.2320 - val_loss: 17.9290 - val_mae: 2.8597 - val_mse: 17.9290\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2630 - mae: 1.7462 - mse: 5.2630 - val_loss: 17.9295 - val_mae: 2.8499 - val_mse: 17.9295\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2244 - mae: 1.7335 - mse: 5.2244 - val_loss: 17.8199 - val_mae: 2.8492 - val_mse: 17.8199\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.2314 - mae: 1.7422 - mse: 5.2314 - val_loss: 17.8562 - val_mae: 2.8542 - val_mse: 17.8562\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2239 - mae: 1.7433 - mse: 5.2239 - val_loss: 17.8277 - val_mae: 2.8372 - val_mse: 17.8277\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2011 - mae: 1.7305 - mse: 5.2011 - val_loss: 17.8598 - val_mae: 2.8612 - val_mse: 17.8598\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.3095 - mae: 1.7501 - mse: 5.3095 - val_loss: 17.8826 - val_mae: 2.8530 - val_mse: 17.8826\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4303 - mae: 1.7768 - mse: 5.4303 - val_loss: 17.8202 - val_mae: 2.8552 - val_mse: 17.8202\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2868 - mae: 1.7442 - mse: 5.2868 - val_loss: 17.8445 - val_mae: 2.8357 - val_mse: 17.8445\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2511 - mae: 1.7394 - mse: 5.2511 - val_loss: 17.9120 - val_mae: 2.8746 - val_mse: 17.9120\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2555 - mae: 1.7555 - mse: 5.2555 - val_loss: 17.8655 - val_mae: 2.8532 - val_mse: 17.8655\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1803 - mae: 1.7223 - mse: 5.1803 - val_loss: 17.8028 - val_mae: 2.8420 - val_mse: 17.8028\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1817 - mae: 1.7326 - mse: 5.1817 - val_loss: 17.8168 - val_mae: 2.8549 - val_mse: 17.8168\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1663 - mae: 1.7292 - mse: 5.1663 - val_loss: 17.8543 - val_mae: 2.8676 - val_mse: 17.8543\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.1521 - mae: 1.7191 - mse: 5.1521 - val_loss: 17.7785 - val_mae: 2.8395 - val_mse: 17.7785\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.2053 - mae: 1.7537 - mse: 5.2053 - val_loss: 17.8015 - val_mae: 2.8506 - val_mse: 17.8015\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.1962 - mae: 1.7199 - mse: 5.1962 - val_loss: 17.8379 - val_mae: 2.8580 - val_mse: 17.8379\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2587 - mae: 1.7505 - mse: 5.2587 - val_loss: 18.0058 - val_mae: 2.8727 - val_mse: 18.0058\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1273 - mae: 1.7320 - mse: 5.1273 - val_loss: 17.9253 - val_mae: 2.8755 - val_mse: 17.9253\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1259 - mae: 1.7204 - mse: 5.1259 - val_loss: 17.8084 - val_mae: 2.8588 - val_mse: 17.8084\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.1254 - mae: 1.7203 - mse: 5.1254 - val_loss: 17.7362 - val_mae: 2.8431 - val_mse: 17.7362\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.0889 - mae: 1.7204 - mse: 5.0889 - val_loss: 17.8337 - val_mae: 2.8667 - val_mse: 17.8337\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.1459 - mae: 1.7174 - mse: 5.1459 - val_loss: 17.7422 - val_mae: 2.8484 - val_mse: 17.7422\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.1090 - mae: 1.7178 - mse: 5.1090 - val_loss: 17.8741 - val_mae: 2.8709 - val_mse: 17.8741\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1016 - mae: 1.7321 - mse: 5.1016 - val_loss: 17.7664 - val_mae: 2.8580 - val_mse: 17.7664\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0853 - mae: 1.7124 - mse: 5.0853 - val_loss: 17.7840 - val_mae: 2.8562 - val_mse: 17.7840\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1573 - mae: 1.7359 - mse: 5.1573 - val_loss: 17.7052 - val_mae: 2.8568 - val_mse: 17.7052\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1013 - mae: 1.7155 - mse: 5.1013 - val_loss: 17.8893 - val_mae: 2.8640 - val_mse: 17.8893\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1290 - mae: 1.7318 - mse: 5.1290 - val_loss: 17.8155 - val_mae: 2.8749 - val_mse: 17.8155\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1394 - mae: 1.7246 - mse: 5.1394 - val_loss: 17.7467 - val_mae: 2.8541 - val_mse: 17.7467\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0709 - mae: 1.7134 - mse: 5.0709 - val_loss: 17.8172 - val_mae: 2.8724 - val_mse: 17.8172\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0306 - mae: 1.7091 - mse: 5.0306 - val_loss: 17.7767 - val_mae: 2.8608 - val_mse: 17.7767\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.0618 - mae: 1.7090 - mse: 5.0618 - val_loss: 17.7139 - val_mae: 2.8566 - val_mse: 17.7139\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.0268 - mae: 1.7098 - mse: 5.0268 - val_loss: 17.7450 - val_mae: 2.8540 - val_mse: 17.7450\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0621 - mae: 1.7096 - mse: 5.0621 - val_loss: 17.6963 - val_mae: 2.8637 - val_mse: 17.6963\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0715 - mae: 1.7266 - mse: 5.0715 - val_loss: 17.7871 - val_mae: 2.8639 - val_mse: 17.7871\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0744 - mae: 1.7124 - mse: 5.0744 - val_loss: 17.7112 - val_mae: 2.8556 - val_mse: 17.7112\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1679 - mae: 1.7289 - mse: 5.1679 - val_loss: 17.7742 - val_mae: 2.8673 - val_mse: 17.7742\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0502 - mae: 1.7288 - mse: 5.0502 - val_loss: 17.6860 - val_mae: 2.8605 - val_mse: 17.6860\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0228 - mae: 1.7051 - mse: 5.0228 - val_loss: 17.7341 - val_mae: 2.8576 - val_mse: 17.7341\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.0383 - mae: 1.7215 - mse: 5.0383 - val_loss: 17.7079 - val_mae: 2.8624 - val_mse: 17.7079\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9790 - mae: 1.7016 - mse: 4.9790 - val_loss: 17.6850 - val_mae: 2.8600 - val_mse: 17.6850\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9786 - mae: 1.6910 - mse: 4.9786 - val_loss: 17.6949 - val_mae: 2.8626 - val_mse: 17.6949\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0055 - mae: 1.7049 - mse: 5.0055 - val_loss: 17.8231 - val_mae: 2.8818 - val_mse: 17.8231\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0402 - mae: 1.7190 - mse: 5.0402 - val_loss: 17.6228 - val_mae: 2.8473 - val_mse: 17.6228\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.9627 - mae: 1.6944 - mse: 4.9627 - val_loss: 17.7438 - val_mae: 2.8764 - val_mse: 17.7438\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0008 - mae: 1.7079 - mse: 5.0008 - val_loss: 17.6366 - val_mae: 2.8593 - val_mse: 17.6366\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9625 - mae: 1.6939 - mse: 4.9625 - val_loss: 17.6500 - val_mae: 2.8510 - val_mse: 17.6500\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0077 - mae: 1.6970 - mse: 5.0077 - val_loss: 17.6944 - val_mae: 2.8695 - val_mse: 17.6944\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.0156 - mae: 1.7140 - mse: 5.0156 - val_loss: 17.6367 - val_mae: 2.8603 - val_mse: 17.6367\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9825 - mae: 1.7085 - mse: 4.9825 - val_loss: 17.7150 - val_mae: 2.8707 - val_mse: 17.7150\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9396 - mae: 1.6913 - mse: 4.9396 - val_loss: 17.6682 - val_mae: 2.8640 - val_mse: 17.6682\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9081 - mae: 1.6928 - mse: 4.9081 - val_loss: 17.6089 - val_mae: 2.8521 - val_mse: 17.6089\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9061 - mae: 1.6854 - mse: 4.9061 - val_loss: 17.6461 - val_mae: 2.8631 - val_mse: 17.6461\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9453 - mae: 1.7035 - mse: 4.9453 - val_loss: 17.6186 - val_mae: 2.8603 - val_mse: 17.6186\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9317 - mae: 1.6891 - mse: 4.9317 - val_loss: 17.5116 - val_mae: 2.8442 - val_mse: 17.5116\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.9186 - mae: 1.6799 - mse: 4.9186 - val_loss: 17.6302 - val_mae: 2.8762 - val_mse: 17.6302\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8967 - mae: 1.6919 - mse: 4.8967 - val_loss: 17.5524 - val_mae: 2.8524 - val_mse: 17.5524\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8737 - mae: 1.6849 - mse: 4.8737 - val_loss: 17.6050 - val_mae: 2.8601 - val_mse: 17.6050\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.9433 - mae: 1.6830 - mse: 4.9433 - val_loss: 17.5554 - val_mae: 2.8609 - val_mse: 17.5554\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8693 - mae: 1.6876 - mse: 4.8693 - val_loss: 17.6210 - val_mae: 2.8632 - val_mse: 17.6210\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.8825 - mae: 1.6863 - mse: 4.8825 - val_loss: 17.6794 - val_mae: 2.8651 - val_mse: 17.6794\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8487 - mae: 1.6858 - mse: 4.8487 - val_loss: 17.5882 - val_mae: 2.8643 - val_mse: 17.5882\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8500 - mae: 1.6822 - mse: 4.8500 - val_loss: 17.5305 - val_mae: 2.8557 - val_mse: 17.5305\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.8854 - mae: 1.6758 - mse: 4.8854 - val_loss: 17.4828 - val_mae: 2.8548 - val_mse: 17.4828\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.9469 - mae: 1.7143 - mse: 4.9469 - val_loss: 17.6233 - val_mae: 2.8639 - val_mse: 17.6233\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9981 - mae: 1.6943 - mse: 4.9981 - val_loss: 17.6856 - val_mae: 2.8660 - val_mse: 17.6856\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8781 - mae: 1.6893 - mse: 4.8781 - val_loss: 17.6670 - val_mae: 2.8769 - val_mse: 17.6670\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.8687 - mae: 1.6913 - mse: 4.8687 - val_loss: 17.6566 - val_mae: 2.8668 - val_mse: 17.6566\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.8821 - mae: 1.6918 - mse: 4.8821 - val_loss: 17.6506 - val_mae: 2.8701 - val_mse: 17.6506\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.8298 - mae: 1.6813 - mse: 4.8298 - val_loss: 17.5481 - val_mae: 2.8595 - val_mse: 17.5481\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8377 - mae: 1.6711 - mse: 4.8377 - val_loss: 17.5199 - val_mae: 2.8593 - val_mse: 17.5199\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8469 - mae: 1.6865 - mse: 4.8469 - val_loss: 17.6343 - val_mae: 2.8659 - val_mse: 17.6343\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8041 - mae: 1.6783 - mse: 4.8041 - val_loss: 17.5762 - val_mae: 2.8636 - val_mse: 17.5762\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8382 - mae: 1.6837 - mse: 4.8382 - val_loss: 17.5617 - val_mae: 2.8612 - val_mse: 17.5617\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8034 - mae: 1.6777 - mse: 4.8034 - val_loss: 17.5953 - val_mae: 2.8652 - val_mse: 17.5953\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7963 - mae: 1.6790 - mse: 4.7963 - val_loss: 17.4835 - val_mae: 2.8532 - val_mse: 17.4835\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.7858 - mae: 1.6736 - mse: 4.7858 - val_loss: 17.5858 - val_mae: 2.8707 - val_mse: 17.5858\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.7641 - mae: 1.6698 - mse: 4.7641 - val_loss: 17.6000 - val_mae: 2.8626 - val_mse: 17.6000\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7561 - mae: 1.6640 - mse: 4.7561 - val_loss: 17.5523 - val_mae: 2.8618 - val_mse: 17.5523\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7771 - mae: 1.6786 - mse: 4.7771 - val_loss: 17.5991 - val_mae: 2.8704 - val_mse: 17.5991\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7586 - mae: 1.6644 - mse: 4.7586 - val_loss: 17.5388 - val_mae: 2.8570 - val_mse: 17.5388\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7651 - mae: 1.6626 - mse: 4.7651 - val_loss: 17.4206 - val_mae: 2.8491 - val_mse: 17.4206\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7427 - mae: 1.6646 - mse: 4.7427 - val_loss: 17.5192 - val_mae: 2.8643 - val_mse: 17.5192\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7616 - mae: 1.6695 - mse: 4.7616 - val_loss: 17.5891 - val_mae: 2.8668 - val_mse: 17.5891\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7551 - mae: 1.6620 - mse: 4.7551 - val_loss: 17.4656 - val_mae: 2.8641 - val_mse: 17.4656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7594 - mae: 1.6709 - mse: 4.7594 - val_loss: 17.5133 - val_mae: 2.8680 - val_mse: 17.5133\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.9035 - mae: 1.6983 - mse: 4.9035 - val_loss: 17.5937 - val_mae: 2.8614 - val_mse: 17.5937\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7687 - mae: 1.6825 - mse: 4.7687 - val_loss: 17.5540 - val_mae: 2.8760 - val_mse: 17.5540\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7677 - mae: 1.6694 - mse: 4.7677 - val_loss: 17.6281 - val_mae: 2.8784 - val_mse: 17.6281\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7718 - mae: 1.6767 - mse: 4.7718 - val_loss: 17.5253 - val_mae: 2.8688 - val_mse: 17.5253\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7390 - mae: 1.6560 - mse: 4.7390 - val_loss: 17.5882 - val_mae: 2.8711 - val_mse: 17.5882\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7246 - mae: 1.6662 - mse: 4.7246 - val_loss: 17.5640 - val_mae: 2.8701 - val_mse: 17.5640\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.6942 - mae: 1.6612 - mse: 4.6942 - val_loss: 17.4661 - val_mae: 2.8619 - val_mse: 17.4661\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.6834 - mae: 1.6594 - mse: 4.6834 - val_loss: 17.4392 - val_mae: 2.8596 - val_mse: 17.4392\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7027 - mae: 1.6535 - mse: 4.7027 - val_loss: 17.4332 - val_mae: 2.8632 - val_mse: 17.4332\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.7028 - mae: 1.6512 - mse: 4.7028 - val_loss: 17.4835 - val_mae: 2.8688 - val_mse: 17.4835\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.6915 - mae: 1.6573 - mse: 4.6915 - val_loss: 17.4698 - val_mae: 2.8651 - val_mse: 17.4698\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7057 - mae: 1.6521 - mse: 4.7057 - val_loss: 17.4700 - val_mae: 2.8677 - val_mse: 17.4700\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.7191 - mae: 1.6612 - mse: 4.7191 - val_loss: 17.6049 - val_mae: 2.8892 - val_mse: 17.6049\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7012 - mae: 1.6673 - mse: 4.7012 - val_loss: 17.4703 - val_mae: 2.8661 - val_mse: 17.4703\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.6614 - mae: 1.6540 - mse: 4.6614 - val_loss: 17.4903 - val_mae: 2.8698 - val_mse: 17.4903\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.7362 - mae: 1.6717 - mse: 4.7362 - val_loss: 17.4528 - val_mae: 2.8683 - val_mse: 17.4528\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "model=initialize_model()\n",
    "model=compile_model(model,\"adam\")\n",
    "history=model.fit(S_X_train, y_train, \n",
    "                  batch_size=16, \n",
    "                  epochs=1000, \n",
    "                  validation_split=0.3,\n",
    "                  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CI8-9wC9EluN",
    "outputId": "6b33af76-e82b-4644-9db7-d4caa048fd57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 23.0408 - mae: 3.1205 - mse: 23.0408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[23.040802001953125, 3.120513916015625, 23.040802001953125]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(S_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMwbWb9DEyta",
    "outputId": "3406628f-15c8-4e5c-c3be-123a52eff834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-hwtnQsJwVK",
    "outputId": "61374f29-53e2-4910-8fb8-a3959ac66635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.661364555358887"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lHyHIADKKe4",
    "outputId": "a6c253f8-bed8-48d1-81ea-22e175919e8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567.6808471679688"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGzBIiJUrRt4"
   },
   "source": [
    "❓ **Question** ❓ Re-run the same model on the same data using different optimizers (in a `for` loop). \n",
    "\n",
    "For each optimizer, plot the history and report the corresponding Mean Absolute Error. (see [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)), as well as the time it took to fit your Neural Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "ZQuXBQgIrRt4"
   },
   "outputs": [],
   "source": [
    "def plot_loss_mae(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=200)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    ax1.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax1.grid(axis=\"y\",linewidth=0.5)    \n",
    "    \n",
    "    ax2.plot(history.history['mae'])\n",
    "    ax2.plot(history.history['val_mae'])\n",
    "    ax2.set_title('MAE')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=20)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    ax2.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax2.grid(axis=\"y\",linewidth=0.5)    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_mse(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=20)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    ax1.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax1.grid(axis=\"y\",linewidth=0.5)    \n",
    "\n",
    "    \n",
    "    ax2.plot(history.history['mse'])\n",
    "    ax2.plot(history.history['val_mse'])\n",
    "    ax2.set_title('MSE')\n",
    "    ax2.set_ylabel('MSE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=200)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    ax2.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax2.grid(axis=\"y\",linewidth=0.5)    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "yu_I9jsSFuhO",
    "outputId": "69248545-0e9e-4383-ca5f-7ea33f025b18"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " plot_loss_mae(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFeag7HcrRt4"
   },
   "source": [
    "❓ **Question** ❓ Are your predictions better than the benchmark model you've evaluated at the beginning of the notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f6owDYTrRt4",
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8PqUxDrrRt5"
   },
   "source": [
    "❗ **Remark** ❗ \n",
    "- Here, the optimizer is may not be central as the data are in low dimensions and and there are not many samples. However, in practice, you are advised to start with the `adam` optimizer by default which often works best. \n",
    "\n",
    "- Internally, when you call any optimizer with a string, the neural network initializes the hyperparameters the optimizer relies on. Among this hyperparameters, there is quite an important one, the **`learning rate`**. This learning rate corresponds to the intensity of change of the weights at each optimization of the neural network. Different learning rates have different consequences, as shown here : \n",
    "\n",
    "<img src=\"learning_rate.png\" alt=\"Learning rate\" style=\"height:350px;\"/>\n",
    "\n",
    "\n",
    "As the learning rate is initialized with default values when you compile the model optimizer with a string, let's see how to do it differently.\n",
    "\n",
    "\n",
    "❓ **Question** ❓ Instead of initializing the optimizer with a string, we will initialize a real optimizer directly. Look at the documentation of [adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and instantiate it with a learning rate of $0.1$ - keep the other values to their default values. Use this optimizer in the `compile_model` function, fit the data and plot the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLHTPl7PrRt5",
    "outputId": "4c108700-0549-4367-e926-306c1b075189",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f52b556a390>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import tensorflow.keras\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(\n",
    "    learning_rate=0.1)\n",
    "\n",
    "def compile_model(model, optimizer_name):\n",
    "  #best metrics\n",
    "  model.compile(loss=\"mse\",optimizer=optimizer_name,metrics=[\"mae\",\"mse\"])\n",
    "  return model\n",
    "\n",
    "compile_model(model,opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gt-MqIgmrRt5"
   },
   "source": [
    "❓ **Question** ❓ Now, reproduce the same plots and results but for different learning rates.\n",
    "\n",
    "*Remark*: There is a chance that the y-axis is too large for you to visualize the results. In that case, rewrite the plot function to plot only the epochs > 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgW4QLVGrRt5",
    "outputId": "7bdc86f2-9b7b-46c5-c36e-9aa765785300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 77.3650 - mae: 6.5911 - mse: 77.3650 - val_loss: 103.8590 - val_mae: 7.4788 - val_mse: 103.8590\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.3622 - mae: 6.5907 - mse: 77.3622 - val_loss: 103.8593 - val_mae: 7.4785 - val_mse: 103.8593\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.3599 - mae: 6.5904 - mse: 77.3599 - val_loss: 103.8596 - val_mae: 7.4782 - val_mse: 103.8596\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.3570 - mae: 6.5901 - mse: 77.3570 - val_loss: 103.8597 - val_mae: 7.4780 - val_mse: 103.8597\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.3546 - mae: 6.5898 - mse: 77.3546 - val_loss: 103.8600 - val_mae: 7.4778 - val_mse: 103.8600\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.3523 - mae: 6.5894 - mse: 77.3523 - val_loss: 103.8602 - val_mae: 7.4775 - val_mse: 103.8602\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 77.3498 - mae: 6.5891 - mse: 77.3498 - val_loss: 103.8605 - val_mae: 7.4772 - val_mse: 103.8605\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 77.3474 - mae: 6.5888 - mse: 77.3474 - val_loss: 103.8607 - val_mae: 7.4770 - val_mse: 103.8607\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 77.3449 - mae: 6.5885 - mse: 77.3449 - val_loss: 103.8610 - val_mae: 7.4768 - val_mse: 103.8610\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 77.3426 - mae: 6.5882 - mse: 77.3426 - val_loss: 103.8612 - val_mae: 7.4765 - val_mse: 103.8612\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 77.3323 - mae: 6.5869 - mse: 77.3323 - val_loss: 103.8635 - val_mae: 7.4744 - val_mse: 103.8635\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.3100 - mae: 6.5837 - mse: 77.3100 - val_loss: 103.8663 - val_mae: 7.4718 - val_mse: 103.8663\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.2844 - mae: 6.5805 - mse: 77.2844 - val_loss: 103.8688 - val_mae: 7.4697 - val_mse: 103.8688\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.2657 - mae: 6.5774 - mse: 77.2657 - val_loss: 103.8726 - val_mae: 7.4667 - val_mse: 103.8726\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 77.2364 - mae: 6.5741 - mse: 77.2364 - val_loss: 103.8750 - val_mae: 7.4648 - val_mse: 103.8750\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.2168 - mae: 6.5712 - mse: 77.2168 - val_loss: 103.8785 - val_mae: 7.4623 - val_mse: 103.8785\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 77.1948 - mae: 6.5682 - mse: 77.1948 - val_loss: 103.8818 - val_mae: 7.4600 - val_mse: 103.8818\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.1749 - mae: 6.5655 - mse: 77.1749 - val_loss: 103.8854 - val_mae: 7.4577 - val_mse: 103.8854\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.1537 - mae: 6.5628 - mse: 77.1537 - val_loss: 103.8885 - val_mae: 7.4557 - val_mse: 103.8885\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 77.1345 - mae: 6.5602 - mse: 77.1345 - val_loss: 103.8922 - val_mae: 7.4535 - val_mse: 103.8922\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 77.0096 - mae: 6.5421 - mse: 77.0096 - val_loss: 103.9479 - val_mae: 7.4266 - val_mse: 103.9479\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.8141 - mae: 6.5173 - mse: 76.8141 - val_loss: 104.0094 - val_mae: 7.4049 - val_mse: 104.0094\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 76.6406 - mae: 6.4954 - mse: 76.6406 - val_loss: 104.0725 - val_mae: 7.3874 - val_mse: 104.0725\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.5143 - mae: 6.4766 - mse: 76.5143 - val_loss: 104.1620 - val_mae: 7.3663 - val_mse: 104.1620\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 76.3777 - mae: 6.4571 - mse: 76.3777 - val_loss: 104.2258 - val_mae: 7.3536 - val_mse: 104.2258\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.2814 - mae: 6.4432 - mse: 76.2814 - val_loss: 104.3075 - val_mae: 7.3392 - val_mse: 104.3075\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 76.1916 - mae: 6.4321 - mse: 76.1916 - val_loss: 104.3868 - val_mae: 7.3273 - val_mse: 104.3868\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.1320 - mae: 6.4163 - mse: 76.1320 - val_loss: 104.4804 - val_mae: 7.3149 - val_mse: 104.4804\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.0532 - mae: 6.4050 - mse: 76.0532 - val_loss: 104.5528 - val_mae: 7.3069 - val_mse: 104.5528\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.0043 - mae: 6.3961 - mse: 76.0043 - val_loss: 104.6222 - val_mae: 7.2997 - val_mse: 104.6222\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 76.1369 - mae: 6.4049 - mse: 76.1369 - val_loss: 104.7025 - val_mae: 7.2924 - val_mse: 104.7025\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.7402 - mae: 6.3256 - mse: 75.7402 - val_loss: 105.8298 - val_mae: 7.2163 - val_mse: 105.8298\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.8453 - mae: 6.2871 - mse: 75.8453 - val_loss: 106.5107 - val_mae: 7.1940 - val_mse: 106.5107\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.7628 - mae: 6.2944 - mse: 75.7628 - val_loss: 105.9187 - val_mae: 7.2128 - val_mse: 105.9187\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.8013 - mae: 6.3044 - mse: 75.8013 - val_loss: 106.0448 - val_mae: 7.2079 - val_mse: 106.0448\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.7246 - mae: 6.3079 - mse: 75.7246 - val_loss: 105.6579 - val_mae: 7.2246 - val_mse: 105.6579\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.7690 - mae: 6.3130 - mse: 75.7690 - val_loss: 105.7553 - val_mae: 7.2194 - val_mse: 105.7553\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 76.0243 - mae: 6.3483 - mse: 76.0243 - val_loss: 105.3808 - val_mae: 7.2411 - val_mse: 105.3808\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.7562 - mae: 6.3147 - mse: 75.7562 - val_loss: 105.7787 - val_mae: 7.2184 - val_mse: 105.7787\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 75.8308 - mae: 6.3188 - mse: 75.8308 - val_loss: 105.7391 - val_mae: 7.2202 - val_mse: 105.7391\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 78.4133 - mae: 6.4194 - mse: 78.4133 - val_loss: 106.7123 - val_mae: 7.1893 - val_mse: 106.7123\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 76.4220 - mae: 6.3625 - mse: 76.4220 - val_loss: 105.6662 - val_mae: 7.2241 - val_mse: 105.6662\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 76.5413 - mae: 6.3946 - mse: 76.5413 - val_loss: 105.6627 - val_mae: 7.2243 - val_mse: 105.6627\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.3694 - mae: 6.3400 - mse: 76.3694 - val_loss: 106.8295 - val_mae: 7.1870 - val_mse: 106.8295\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.7330 - mae: 6.4270 - mse: 76.7330 - val_loss: 108.5785 - val_mae: 7.1674 - val_mse: 108.5785\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.6769 - mae: 6.2714 - mse: 76.6769 - val_loss: 104.9567 - val_mae: 7.2714 - val_mse: 104.9567\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.2548 - mae: 6.3660 - mse: 76.2548 - val_loss: 105.0219 - val_mae: 7.2664 - val_mse: 105.0219\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.1372 - mae: 6.3415 - mse: 76.1372 - val_loss: 109.4687 - val_mae: 7.1609 - val_mse: 109.4687\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 75.7690 - mae: 6.2466 - mse: 75.7690 - val_loss: 104.6357 - val_mae: 7.2984 - val_mse: 104.6357\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 78.3220 - mae: 6.5927 - mse: 78.3220 - val_loss: 113.0578 - val_mae: 7.1710 - val_mse: 113.0578\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 76.4479 - mae: 6.3764 - mse: 76.4479 - val_loss: 108.2377 - val_mae: 7.1700 - val_mse: 108.2377\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 77.7807 - mae: 6.4317 - mse: 77.7807 - val_loss: 104.3303 - val_mae: 7.3357 - val_mse: 104.3303\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.7994 - mae: 6.3412 - mse: 76.7994 - val_loss: 106.0894 - val_mae: 7.2064 - val_mse: 106.0894\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 77.5039 - mae: 6.3570 - mse: 77.5039 - val_loss: 104.6909 - val_mae: 7.8117 - val_mse: 104.6909\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 77.7974 - mae: 6.4969 - mse: 77.7974 - val_loss: 104.3440 - val_mae: 7.3336 - val_mse: 104.3440\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 78.5903 - mae: 6.3941 - mse: 78.5903 - val_loss: 104.3601 - val_mae: 7.3312 - val_mse: 104.3601\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.8569 - mae: 6.4561 - mse: 76.8569 - val_loss: 107.7815 - val_mae: 7.1736 - val_mse: 107.7815\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.1316 - mae: 6.3909 - mse: 77.1316 - val_loss: 107.2566 - val_mae: 7.1803 - val_mse: 107.2566\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 77.2590 - mae: 6.3702 - mse: 77.2590 - val_loss: 104.7399 - val_mae: 7.2891 - val_mse: 104.7399\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 76.5595 - mae: 6.4457 - mse: 76.5595 - val_loss: 125.4239 - val_mae: 7.5284 - val_mse: 125.4239\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 5]\n",
    "\n",
    "for lr in learning_rates:\n",
    "  opt = tensorflow.keras.optimizers.Adam(\n",
    "    learning_rate=lr)\n",
    "  \n",
    "  model2=compile_model(model,opt)\n",
    "  history=model2.fit(S_X_train, y_train, \n",
    "                  batch_size=16, \n",
    "                  epochs=10, \n",
    "                  validation_split=0.3,\n",
    "                  callbacks=[es])\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "pA0n48wROqHT",
    "outputId": "a9650548-7ad2-4547-dc26-569c9591097f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_mae(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-uHnD8GQApP",
    "outputId": "da5c152f-dcff-42f1-942a-966e18b881aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 102.1103 - mae: 7.3829 - mse: 102.1103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[102.11029052734375, 7.382901668548584, 102.11029052734375]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(S_X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPAEstr_rRt5"
   },
   "source": [
    "# 3. The loss\n",
    "\n",
    "⚠️ It is important to **clearly understand the different between metrics and losses**. \n",
    "\n",
    "* The `loss functions` are computed *during* the training procedure\n",
    "* The `metrics` are computed *after* training your models !\n",
    "* Some metrics can be used as loss functions too... as long as they are differentiable ! (e.g. the *MSE*)\n",
    "\n",
    "❓ **Question** ❓ Run the same neural network, once with the `mae` as the loss, and once with the `mse`.  \n",
    "\n",
    "In both case, compare `mae_train`, `mae_val`, `mse_train`, `mse_val` and conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tJTGxLgOspu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvexYchMrRt5",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6nLXIQxrRt5"
   },
   "source": [
    "❗️ Countrary to first intuition, it can be sometimes better to use the MSE as the loss function in order to get the best MAE possible in the end!\n",
    "\n",
    "<details>\n",
    "    <summary>▶ Why?</summary>\n",
    "\n",
    "Well, even the Deep Learning research community is still trying to answer these types of questions rigorously.\n",
    "    \n",
    "One thing for sure: In Deep Learning, you will never really reach the \"global minimum\" of the true loss function (the one computed using your entire training set as one single \"batch\"). So, in your first model (minimizing the MAE loss), your global MAE minimum has clearly **not** been reached (otherwise you could never beat it). \n",
    "\n",
    "Why? It may well be that the minimization process of the second model has performed better. Maybe because the loss function \"energy map\" is \"smoother\" or more \"convex\" in the case of MSE loss? Or maybe your hyper-parameter are best suited to the MSE than to the MAE loss?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82DSHY8XrRt5"
   },
   "source": [
    "### 🧪 Test your model best performance\n",
    "\n",
    "❓ Save your best model performance on the test set at `mae_test` and check it out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "29QYyYP4rRt6",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "mae_test=3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Yxz8BOjPQ8D"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pFFiG3YTrRt6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /Users/shu/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/shu/Desktop/Lewagon/code/shiro101010101/data-challenges/06-Deep-Learning/02-Optimizer-loss-and-fitting/03-Finetune-your-Neural-Network\n",
      "plugins: dash-2.0.0, anyio-3.3.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_solution.py::TestSolution::test_is_score_ok \u001b[32mPASSED\u001b[0m\u001b[32m            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/solution.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed solution step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('solution',\n",
    "    mae_test = mae_test)\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoKaSFxSrRt6"
   },
   "source": [
    "# 4 : Save and load a model\n",
    "\n",
    "❓ **Question** ❓  Save your model using `.save_model(model, 'name_of_my_model')` method that you can find [here](https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGDajnE9rRt6",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m31IBd5UrRt6"
   },
   "source": [
    "❓ **Question** ❓ Now, in a variable that you will call `loaded_model`, load the model you just saved thanks to `.load_model('name_of_your_model')` [(documentation here)](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model), and evaluate it on the test data to check that it gives the same result as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcPgU--WrRt6",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqlpMZDjrRt6"
   },
   "source": [
    "## (Optional) `Exponential Decay` for the Optimizer's Learning Rate\n",
    "\n",
    "The next question is not essential and can be skipped as many algorithms can be run without such optimization. \n",
    "\n",
    "Instead of keeping a fixed learning rate, you can change it from one iteration to the other, with the intuition that at first, you need large learning rates, and as the neural network converges and get closer to the minimum loss value, you can decrease the value of the learning rate. This is called a **`scheduler`**. \n",
    "\n",
    "❓ **Question** ❓ Use the [Exponential Decay Scheduler](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay) in the `adam` optimizer and run it on the previous data. Start with the following:\n",
    "\n",
    "```python\n",
    "initial_learning_rate = 0.001 # start with default ADAM value\n",
    "\n",
    "lr_schedule = ExponentialDecay(\n",
    "    # Every 5000 iterations, multiply the learning rate by 0.7\n",
    "    initial_learning_rate, decay_steps=5000, decay_rate=0.7,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qzgk-xg4rRt6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxDiT3E7rRt6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Finetune-your-neural-network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
