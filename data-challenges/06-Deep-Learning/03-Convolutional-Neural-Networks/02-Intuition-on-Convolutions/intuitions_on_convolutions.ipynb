{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition on Convolutions\n",
    "\n",
    "**Objectives**\n",
    "- Compute convolution operations\n",
    "- Visualize a convolution kernel\n",
    "- VIsualize the effect of a convolution on images\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "**Convolutional Neural Networks** correspond the Neural Networks that are specially designed to work on images. \n",
    "\n",
    "This is made possible thanks to _convolutions_. This specific mathematical operations applies a _kernel_ to an input image and creates an output representation. The name of this output can change depending on the community. Here, let's talk about the output as it corresponds to the output of a layer, as in standard DL neurons. But it can also be \"convoluted representation/feature\", \"convolution\", or also \"activation\" as it corresponds to the activation of a given layer.\n",
    "\n",
    "<img src=\"convolution.png\" width=\"300\">\n",
    "\n",
    "⚠️ It is important to get that the same kernel, i.e. the same weights, are applied to different zones of the images. This is very different from standard DL operations where each weight of each neuron is related to only one input coordinate (which in this case would be each pixel). Here, the weight of a kernel is not applied to only one input, i.e. one pixel, but to different pixels, \"step by step\".\n",
    "\n",
    "You can think of each kernel (or each filter in case of color image) as a magnifying glass through which you see the image. Similarly to your eyes which have to do not capture everything at once, but that have to look at different parts before to capture the whole thing you are looking at.\n",
    "\n",
    "So let's see a bit deeper at convolutions in general, and their impact in Convolutional Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "❓ First use the following function to load the data. \n",
    "\n",
    "⚠️ Restrict any desire to change the shapes or types of the outputs, this can arm further questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_data(path):\n",
    "    nb_circles = 100\n",
    "    nb_triangles = 100\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(nb_circles):\n",
    "        c_path = os.path.join(path, 'circles', f'circle_{i}.png')\n",
    "        X.append(imread(c_path)[:, :, :1])\n",
    "        y.append(0)\n",
    "    \n",
    "    for i in range(nb_triangles):\n",
    "        t_path = os.path.join(path, 'triangles', f'triangle_{i}.png')\n",
    "        X.append(imread(t_path)[:, :, :1])\n",
    "        y.append(1)\n",
    "        \n",
    "    c = list(zip(X, y))\n",
    "    np.random.shuffle(c)\n",
    "    X, y = zip(*c)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "        \n",
    "X, y = load_data('data')\n",
    "# Replace data by \"https://wagon-public-datasets.s3.amazonaws.com/deep-learning-circles-triangles\" if you are on a server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Check the shape of your data. Especially, why an additional dimension of size 1 for `X`? \n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "The last dimension corresponds to the grey (black & white) channel - contrary to RGB images that \n",
    "have 3 channels, one for each color\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Do the input images need some normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Display some images with `plt.imshow` and their respective label (the images are black and white, therefore use `cmap=gray` in the dedicated matplotlib function - otherwise, you will get unrelevant and weird colors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ How many classes to predict are there? It should already give you an information on the last layer of your CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Kernels\n",
    "\n",
    "The following function allows to apply a kernel to an image => a convolution. \n",
    "\n",
    "⚠️ Be careful though as _convolution_ operation are slighlty different in signal processing. For instance, the numpy.convolve function does not compute the convolution in the Deep Learning sense.\n",
    "\n",
    "⚠️ Keras convolutions are a bit more complex as they deal with padding and slide. This is a simplified example.\n",
    "\n",
    "⚠️ Be careful: convolution sometimes refers to _one_ operation. Sometimes to the operations repeated on the entire image.\n",
    "\n",
    "❓ Load the function and go through the lines to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_convolution(img, kernel):\n",
    "    # Parameters\n",
    "    kernel = np.array(kernel)\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    img = np.squeeze(img) # Removes dimensions of size 1\n",
    "    img_height, img_width = img.shape\n",
    "    \n",
    "    array = []\n",
    "\n",
    "    for x in range(img_height-kernel_height):\n",
    "        arr = []\n",
    "        \n",
    "        for y in range(img_width - kernel_width):\n",
    "            \n",
    "            a = np.multiply(img[x:x+kernel_height, y:y+kernel_width], kernel)\n",
    "            arr.append(a.sum())\n",
    "            \n",
    "        array.append(arr)\n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Apply the convolution with the following kernel to any image from the input dataset. Display the input and output image to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_kernel = [\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous kernel corresponds to the _identity_ kernel, meaning that the output is equal to the output... It basically does nothing. You can easily figure this out by thinking about the operation it does on the image : only one pixel per convolution operation is kept as the other are multiplied by 0.\n",
    "\n",
    "❓ `plot_convolution` with the following `kernel_1`, once on an triangle and once on a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_1 = [\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0],\n",
    "    [-1, -1, -1]\n",
    "]\n",
    "\n",
    "def plot_convolution(img, kernel, activation=False):\n",
    "    ''' The following printing function ease the visualization'''\n",
    "    \n",
    "    img = np.squeeze(img)\n",
    "    output_img = compute_convolution(img, kernel)\n",
    "    if activation:\n",
    "        output_img = np.maximum(output_img, 0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ax1 = plt.subplot2grid((3,3),(0,0), rowspan=3)\n",
    "    ax1.imshow(img, cmap='gray')\n",
    "    ax1.title.set_text('Input image')\n",
    "    \n",
    "    ax2 = plt.subplot2grid((3,3),(1, 1))\n",
    "    ax2.imshow(kernel, cmap='gray')\n",
    "    ax2.title.set_text('Kernel')    \n",
    "    \n",
    "    ax3 = plt.subplot2grid((3,3),(0, 2), rowspan=3)\n",
    "    ax3.imshow(output_img, cmap='gray')\n",
    "    ax3.title.set_text('Output image')    \n",
    "\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Let's try to understand why this is meaningful. First, white colors correspond to high values and black to low values. In a neural network, just after a regular neuron or a convolution, there is an activation function. When the activation function is a `relu`, it just correponds to setting the negative values to 0.\n",
    "\n",
    "Well, let's see what it means in the case of a CNN. Re-run the previous functions with `activation` set to `True` (in this case, the activation fuction _is_ the relu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ This kernel is actually highlithing the edges in a given direction. Try the next following kernels to check the different edges it can detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = [\n",
    "    [-1, -1, -1],\n",
    "    [0, 0, 0],   \n",
    "    [1, 1, 1],\n",
    "]\n",
    "\n",
    "kernel_3 = [\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 1]\n",
    "]\n",
    "\n",
    "kernel_4 = [\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ What the effect of kernel size? Check it out with a larger kernel of shape (10,10) below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_big = np.array([\n",
    "    np.ones((10,)),\n",
    "    np.ones((10,)),\n",
    "    np.ones((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.zeros((10,)),\n",
    "    np.ones((10,))*-1,\n",
    "    np.ones((10,))*-1,\n",
    "    np.ones((10,))*-1,\n",
    "])\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Feel free to try any other kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_kernel = np.random.uniform(-10, 10, (5, 5))\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you got the idea of what the convolution is doing, let's see how it goes in a real Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Convolutional Neural Network\n",
    "\n",
    "\n",
    "❓ Write a convolutional network that has \n",
    "- a convolutional layer with 16 filters with (4, 4) kernels.\n",
    "- a convolutional layer with 32 filters with (3, 3) kernels.\n",
    "- a convolutional layer with 32 filters with (3, 3) kernels.\n",
    "- a convolutional layer with 32 filters with (2, 2) kernels.\n",
    "\n",
    "with:\n",
    "- A max-pooling layer (with (2, 2) pool sizes) after each convolution.\n",
    "- A Dense layer of the size of your choice - be reasonable - after the flattening and before the last layer\n",
    "\n",
    "\n",
    "Also, be sure to compile your model with the adequate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    pass # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Fit the model. You should achieve a accuracy of at least 90. Here, the point is not to bother with overfitting, so do not worry much as you would have to if you have a high score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to retrieve the values of the different kernels in the CNN. Look at the following method that will return the value of a kernel depending on:\n",
    "- the layer number, which can be only `0 `or `2`, as the convolution layers correspond to the first and third layer of the CNN\n",
    "- the filter number, where there is 32 filters in the first convolution, and 64 filters in the second convolution\n",
    "- the channel number, where there is 1 channel in the first convolution, and 32 channels in the second convolution\n",
    "\n",
    "\n",
    "❓  Using `plot_convolution(activation=True)`, display some kernels from the FIRST convolutional layer, along with the activation output, to see what the model has learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(layer_number, filter_number, channel_number):\n",
    "\n",
    "    weight_or_bias = 0\n",
    "    k = model.layers[layer_number].weights[0].numpy()[:,\n",
    "                                                      :,\n",
    "                                                      channel_number,\n",
    "                                                      filter_number]\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have only looked at the activation (\"output image\") of the **first** layer.\n",
    "\n",
    "In order to visualize the activation of the CNN after the second convolution, we need to compute the activations after the first layer, then compute the MaxPooling, then second convolution activation, etc...\n",
    "\n",
    "We give you below a function below which does exactly that: It computes the different activation through the entire network, and store them in an list. Notice that it uses keras `Fonctional API`\n",
    "\n",
    "❓ Run the following cell. The function allows to directly print the activation after any layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all 9 layers\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "# Instanciate 9 sub-models: [layer1, layer1-->layer2, layer1-->layer2-->layer3, ...]\n",
    "# Reusing already trained weights and biases\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# Compute the 9 output of each sub-models\n",
    "activations = activation_model.predict(X) \n",
    "\n",
    "def get_activation(activations, image_number, layer_number, filter_number):\n",
    "    '''return activation map for a given layer, image, and filter number'''\n",
    "    return activations[layer_number][image_number][:, :, filter_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Choose one image, and display the 3 activation \"images\" of each 3 convolution layers. Pick for instance the first filter of each layer. \n",
    "- Notice how the information of an image **flows** within the network.\n",
    "- You should see picture become more and more \"abstract\", of smaller and smaller \"dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 **Congratulation! Don't forget to commit and push your notebook** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils (appendix)\n",
    "\n",
    "The following simply presents the functions that created the dataset you are working with.\n",
    "\n",
    "They were left at the end of the notebook in case you want to further prototype and get better understanding of what is going on. But do not prototype yet => you can go to the next exercise as for now, and come back to it any time later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_triangle():\n",
    "    dx = np.random.uniform(0.1, 0.3)\n",
    "    dy = np.random.uniform(0.1, 0.3)\n",
    "    noise_x = np.random.uniform(0.0, 0.1)\n",
    "    noise_y = np.random.uniform(0.0, 0.1)    \n",
    "    \n",
    "    x = np.random.uniform(0, 1-dx-noise_x)\n",
    "    y = np.random.uniform(0, 1-dy)\n",
    "    X = np.array([[x,y], [x+dx+noise_x,y], [x+dx/2, y+dy+noise_y]])\n",
    "\n",
    "    t1 = plt.Polygon(X, color='black')\n",
    "    plt.gca().add_patch(t1)\n",
    "    \n",
    "def draw_circle():\n",
    "    r = np.random.uniform(0.1, 0.25)\n",
    "    x = np.random.uniform(0+r, 1-r)\n",
    "    y = np.random.uniform(0+r, 1-r)\n",
    "\n",
    "    circle1 = plt.Circle((x, y), r, color='black')\n",
    "    plt.gcf().gca().add_artist(circle1)\n",
    "    \n",
    "def create_image(form, path):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if form == 'circle':\n",
    "        draw_circle()\n",
    "    elif form == 'triangle':\n",
    "        draw_triangle()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(path, dpi=80, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def create_images(path):\n",
    "    nb_circles = 100\n",
    "    nb_triangles = 100\n",
    "    \n",
    "    for i in range(nb_circles):\n",
    "        c_path = os.path.join(path, 'circles', f'circle_{i}.png')\n",
    "        create_image('circle', c_path)\n",
    "        \n",
    "    for i in range(nb_triangles):\n",
    "        t_path = os.path.join(path, 'triangles', f'triangle_{i}.png')\n",
    "        create_image('triangle', t_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
