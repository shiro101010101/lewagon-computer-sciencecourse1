{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEt4AJqKVj0v"
   },
   "source": [
    "# CIFAR Classification\n",
    "\n",
    "### Exercise objectives\n",
    "\n",
    "- Implement a CNN for a 10-class classification problem\n",
    "- Enhance the CNN performance with data augmentation techniques\n",
    "- Experiment the acceleration of GPU for image processing (Google Colab)\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "You should now have a better feeling of how a CNN is working, and especially how the convolutions are affecting the image to detect specific features. Therefore, let's now play with a bit more complex images. \n",
    "\n",
    "The CIFAR-10 dataset is a dataset that contains images of 10 different classes \n",
    "\n",
    "<img src=\"https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/mini-projets/cifar10_notebook_fichiers/cifar_10.png\">\n",
    "\n",
    "This dataset is emblematic in the research community as many enhancements for image problems have been achieved on this dataset, and later on the CIFAR-100 dataset once the performance got too high. You can check the [wikipedia](https://en.wikipedia.org/wiki/CIFAR-10) page of the dataset if you want to know more about it.\n",
    "\n",
    "In this notebook, we propose to implement a CNN to distinguish the 10 categories from the CIFAR-10 dataset. Again, remember that until 10 years ago, this problem was very challenging to the entire research community and is now for you to tackle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE3R20SasW6i"
   },
   "source": [
    "## 0. Colab\n",
    "\n",
    "**First, make sure to use GPU acceleration** by clicking on `\"Runtime --> Change runtime --> GPU\"` if you are on Colab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY44N5e6T2Il"
   },
   "source": [
    "## 1. Data\n",
    "\n",
    "We'll take care of data loading and preprocessing for you. Just run the following cells and make sure you understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16493,
     "status": "ok",
     "timestamp": 1619681093737,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "ZkKdhZXWVj00",
    "outputId": "6d5cf9e1-b3b9-4728-cbd3-618990fb680e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "(images_train, labels_train), (images_test, labels_test) = cifar10.load_data()\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(images_train.shape, images_test.shape)\n",
    "unique, counts = np.unique(labels_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZI_3K-MHT2In"
   },
   "source": [
    "‚ùóÔ∏è 50,000 images may take a long time to train: **Always start with a subsample to iterate quickly** before scaling up\n",
    "\n",
    "Below, we divide the dataset size by `reduction_factor=10`. Don't try to increase it unless we ask you too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1619681314218,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "wR_JXHmlT2Io",
    "outputId": "1732fcfc-3227-43e9-b2bd-f1257ea48755"
   },
   "outputs": [],
   "source": [
    "# Reduce size\n",
    "reduction_factor = 10\n",
    "\n",
    "idx_train =  np.random.choice(len(images_train), round(len(images_train)/reduction_factor))\n",
    "idx_test =  np.random.choice(len(images_test), round(len(images_test)/reduction_factor))\n",
    "\n",
    "images_train_small = images_train[idx_train]\n",
    "images_test_small = images_test[idx_test]\n",
    "labels_train_small = labels_train[idx_train]\n",
    "labels_test_small = labels_test[idx_test]\n",
    "\n",
    "print(images_train.shape, images_test.shape)\n",
    "unique, counts = np.unique(labels_train_small, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1619681318700,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "hQ62jK5VVj03",
    "outputId": "5dfa91d5-48ad-4fae-8e9f-a09b13b0b611"
   },
   "outputs": [],
   "source": [
    "# Let's plot few images to see what they look like\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(6):\n",
    "    plt.subplot(1,6, i+1)\n",
    "    img = images_train[i]\n",
    "    label = labels_train[i][0]\n",
    "    plt.imshow(img)\n",
    "    plt.title(labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMG4ttoHVj02"
   },
   "source": [
    "And, as usual,\n",
    "- we normalize the data between 0 and 1\n",
    "- we create `y` as one-hot-encoded version of `labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 2009,
     "status": "ok",
     "timestamp": 1619681319177,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "Fm8XRTbiVj02"
   },
   "outputs": [],
   "source": [
    "X_train = images_train / 255.\n",
    "X_train_small = images_train_small / 255.\n",
    "X_test = images_test / 255.\n",
    "X_test_small = images_test_small / 255.\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(labels_train, 10)\n",
    "y_train_small = to_categorical(labels_train_small, 10)\n",
    "y_test = to_categorical(labels_test, 10)\n",
    "y_test_small = to_categorical(labels_test_small, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke9YJk7MVj04"
   },
   "source": [
    "## 2. Iterate on your CNN architecture using your small training set\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì Your turn to shine!\n",
    "\n",
    "- Define the CNN architecture of your choice in a method `initialize_model()`\n",
    "- Compile your model in a method `compile_model()`:\n",
    "- Fit it on your **small** training set **only**\n",
    "- Store the output of the fit in an `history` variable\n",
    "- Try a first model yourself, before looking at PRO TIPS below\n",
    " \n",
    "<details>\n",
    "    <summary> üÜò PRO TIPS üÜò  </summary>\n",
    "\n",
    "\n",
    "- Do not forget to add the input shape of your data to the first layer: it has 3 colors\n",
    "- Start simple, complexify after few trials to get better results\n",
    "- The task is complex: Try at least 3 or 4 convolutions\n",
    "- Kernel size do not need to be large for such small picture resolution!\n",
    "- Add some Maxpooling (but not too much else the activation \"image\" will become too small)\n",
    "- Keep padding = 'same' and 'stride' = (1,1) to start with.\n",
    "- Once your model overfits, try adding some dropout layer to regularize the network. A good tip is too increase dropout strengh as you move closer to the output, so as not to overfit on your end-result\n",
    "- Images are so small, that you can use larger batch size (32 or 64) to benefit from even more GPU parallelization\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 1498,
     "status": "ok",
     "timestamp": 1619681319178,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "GNOtE5xhVj04"
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    '''instanciate and return the CNN architecture of your choice with less than 150,000 params'''\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1619681319179,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "7C9AL4uBT2Iq"
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    '''return a compiled model suited for the cifar tasks'''\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcPQtVjdVj06"
   },
   "source": [
    "‚ùì **Question** ‚ùì Run the following function on the previous history (keep the default arguments, these are intended for future plots in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1619681397197,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "lIR_L7UfVj06"
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR7l9LxMVj07"
   },
   "source": [
    "‚ùì **Question** ‚ùì Evaluate your model on the test data and compare it with baseline. Are you satisfied with these performances ? Look at PRO TIPS above and iterate a bit if you want to improve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1619681399234,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "WwnwvmV5Vj08",
    "outputId": "f5e17e5f-41ff-48fb-e961-b0c53c118d66",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7P9y-LwVjdx"
   },
   "source": [
    "## 3. Increase data size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMHH_qsbVT_0"
   },
   "source": [
    "‚ùì **Question** ‚ùì Now that your model fits on a small subsample, try to fit it on the full dataset and notice how performance increases. \n",
    "\n",
    "üö® **Make sure to use GPU acceleration** by clicking on `\"Runtime --> Change runtime --> GPU\"` if you are on Colab. \n",
    "\n",
    "üí° Training neural network on images (in each batch) can be parallelized, and this parallelization procedure can be done on GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "pWHicYsosW6o"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk8ZZVunVj08"
   },
   "source": [
    "## 4. Data augmentation\n",
    "\n",
    "‚òùÔ∏è It seems that adding pictures greatly improves model performance! Welcome to the Deep Learning paradigm, where big data does make a difference.\n",
    "\n",
    "To easily improve the accuracy of a model without much work, we can generate new data: the _data augmentation_. This widely used technique consists in applying little transformation to input images without changing its label, as mirroring, cropping, intensity changes, etc. The improved performance simply results from the Neural network training with more different data.\n",
    "\n",
    "The natural way to generate these new images is to apply some transformations and train the model on the original and new images. However, such procedure requires to keep all these images in memory : it can be very intensive, to the point that your computer memory cannot hold any new image (your computer might even crash).\n",
    "\n",
    "For this reason, we will augment the data **on the fly** (batch per batch), meaning that we will create new data, use them to fit the model, then delete them. Here, Keras is our friend as it provides the utils to do all this job for us. Look at the following code : the general writing can seem odd but don't be panicked: just look at the function arguments that defines the augmentation techniques that we will use and that you can check in the  [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163449,
     "status": "ok",
     "timestamp": 1619623286033,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "DlOpbos5Vj09",
    "outputId": "b21acfa3-8d9f-42cb-c130-f4c193e88231"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    ) \n",
    "\n",
    "datagen.fit(X_train)\n",
    "datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163749,
     "status": "ok",
     "timestamp": 1619623286340,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "Zcl17dW1aA0G",
    "outputId": "370101ad-cb62-4f51-bd8d-568191d57556"
   },
   "outputs": [],
   "source": [
    "X_augmented_iterator = datagen.flow(X_train, shuffle=False, batch_size=1)\n",
    "X_augmented_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdMqg8grVj09"
   },
   "source": [
    "üí° Always visualize your data augmentation in order to double check that you can still recognize the label yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 166091,
     "status": "ok",
     "timestamp": 1619623288689,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "IsqMF0adVj09",
    "outputId": "5bb32536-a174-423a-fc4e-fc0e82bc4d68"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, (raw_image, augmented_image) in enumerate(zip(X_train, X_augmented_iterator)):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n",
    "    ax1.imshow(raw_image)\n",
    "    ax2.imshow(augmented_image[0])\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyLlJQrKVj09"
   },
   "source": [
    "‚ùó **Remark** ‚ùó In this example, there is one augmented image per initial image. In fact, when your model will use `datagen.flow` in the `fit`, it will create one augmentation per epochs! Indeed, the images in the original dataset will not be provided to the optimizer, only augmented ones instead. (But because the augmentations are performed randomly, this allows both modified images and some very close of the originals).\n",
    "\n",
    "‚ùì **Question** ‚ùì Take time to understand the cell below: Previously, we used the `validation_split` argument to let the model separate a training set from the validation one. It is not possible here as **using an image in the training set and its transformation in the validation set is considered as a data leakage**. Therefore, we have to manually define the `validation_data` with the following commands:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lYOkY7LOVj09"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# The model\n",
    "model_aug = initialize_model()\n",
    "model_aug = compile_model(model_aug)\n",
    "\n",
    "# The data generator\n",
    "X_tr = X_train[:40000]\n",
    "y_tr = y_train[:40000]\n",
    "X_val = X_train[40000:]\n",
    "y_val = y_train[40000:]\n",
    "train_flow = datagen.flow(X_tr, y_tr, batch_size=64)\n",
    "\n",
    "# The early stopping criterion\n",
    "es = EarlyStopping(patience=3)\n",
    "\n",
    "# The fit\n",
    "history_aug = model_aug.fit(train_flow, \n",
    "                        epochs=50, \n",
    "                        callbacks=[es], \n",
    "                        validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmQ9t_cMVj0-"
   },
   "source": [
    "‚ùóÔ∏è‚ùóÔ∏è Remark ‚ùóÔ∏è‚ùóÔ∏è: The training can be quite long here. Don't hesitate to go to the next exercise and gome back once in a while to finish the last questions\n",
    "\n",
    "‚ùì **Question** ‚ùì Now, let's plot the previous and current run histories. What do you think of the data augmentation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515585,
     "status": "ok",
     "timestamp": 1619623638195,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "o9r4Fau2Vj0-",
    "outputId": "bd72c691-c91e-49d8-9ad3-74e63763bacb",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm055RyNVj0-"
   },
   "source": [
    "üí° Data augmentation may not improve your performance easily. It strongly depends on the model architecture you used, the learning rate, the type of augmentation chosen, etc...Image classification is an art that takes lots of practice to master!\n",
    "\n",
    "üö® **Don't spend too much time now trying to finetune your model - you have other interesting challenge ahead**. \n",
    "\n",
    "üìö [here is a good example of solution for future reference](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/). They manage to get about 80% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy4DCYLGVj0-"
   },
   "source": [
    "### üèÅ Congratulation üèÅ \n",
    "Copy this notebook from your google drive into your local data-challenge repo, and commit+push your progress on github. To find where this Colab notebook has been save, click on `File --> Locate in Drive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fkYuyP0_vdl2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
